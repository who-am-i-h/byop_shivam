{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1994695,
          "sourceType": "datasetVersion",
          "datasetId": 1193002
        }
      ],
      "dockerImageVersionId": 30635,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "parsasam_captcha_dataset_path = kagglehub.dataset_download('parsasam/captcha-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4Axdk23khuX",
        "outputId": "49bbbc7e-6883-45bb-a16f-f08ba6678196"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/parsasam/captcha-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 356M/356M [00:04<00:00, 91.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sys import getsizeof\n",
        "from datetime import datetime\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:31.142593Z",
          "iopub.execute_input": "2024-04-05T13:41:31.14293Z",
          "iopub.status.idle": "2024-04-05T13:41:31.155554Z",
          "shell.execute_reply.started": "2024-04-05T13:41:31.142907Z",
          "shell.execute_reply": "2024-04-05T13:41:31.154672Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1XD2v5Pjkhub",
        "outputId": "44136896-1359-46c8-8c28-1c92111bc0aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_dir = parsasam_captcha_dataset_path\n",
        "image_paths = sorted(list(glob.glob(f\"{data_dir}/*.jpg\")))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:31.643127Z",
          "iopub.execute_input": "2024-04-05T13:41:31.64379Z",
          "iopub.status.idle": "2024-04-05T13:41:32.086033Z",
          "shell.execute_reply.started": "2024-04-05T13:41:31.643756Z",
          "shell.execute_reply": "2024-04-05T13:41:32.085101Z"
        },
        "trusted": true,
        "id": "l5j3KPg_khub"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gt_list = [i[-9:-4] for i in image_paths]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:32.08737Z",
          "iopub.execute_input": "2024-04-05T13:41:32.08763Z",
          "iopub.status.idle": "2024-04-05T13:41:32.117217Z",
          "shell.execute_reply.started": "2024-04-05T13:41:32.087608Z",
          "shell.execute_reply": "2024-04-05T13:41:32.116262Z"
        },
        "trusted": true,
        "id": "kfXIrV99khuc"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:32.438534Z",
          "iopub.execute_input": "2024-04-05T13:41:32.439265Z",
          "iopub.status.idle": "2024-04-05T13:41:32.443725Z",
          "shell.execute_reply.started": "2024-04-05T13:41:32.439231Z",
          "shell.execute_reply": "2024-04-05T13:41:32.4428Z"
        },
        "trusted": true,
        "id": "_lvnHAgikhuc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "characters = np.array([list(gt) for gt in gt_list]).flatten()\n",
        "list_char = sorted(list(set(characters)))\n",
        "print(\"list_char\", list_char)\n",
        "print('len(list_char)', len(list_char))\n",
        "CHAR_PER_LABEL = 5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:32.627679Z",
          "iopub.execute_input": "2024-04-05T13:41:32.628045Z",
          "iopub.status.idle": "2024-04-05T13:41:33.123835Z",
          "shell.execute_reply.started": "2024-04-05T13:41:32.628016Z",
          "shell.execute_reply": "2024-04-05T13:41:33.122899Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ30Ti6Ykhuc",
        "outputId": "112a9f90-177a-4a59-cb09-687114e24d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list_char ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "len(list_char) 60\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "def char_to_1_hot(char: str):\n",
        "    out = np.zeros(len(list_char))\n",
        "    idx = list_char.index(char)\n",
        "    out[idx] = 1\n",
        "    return out\n",
        "\n",
        "\n",
        "def one_hot(characters: str):\n",
        "    return np.hstack([char_to_1_hot(c) for c in characters]).astype('uint8')\n",
        "\n",
        "def one_hot_to_char(x: np.array):\n",
        "    y = np.array(x)\n",
        "    y = y.squeeze()\n",
        "    assert len(y) == len(list_char)\n",
        "    idx = np.argmax(y)\n",
        "    return(list_char[idx])\n",
        "\n",
        "\n",
        "def one_hot_to_label(x):\n",
        "    y = np.array(x)\n",
        "    y = y.squeeze()\n",
        "    label_list = []\n",
        "    assert len(y) == len(list_char * CHAR_PER_LABEL)\n",
        "    for i in range(0, CHAR_PER_LABEL):\n",
        "        start = i * len(list_char)\n",
        "        end = start + len(list_char)\n",
        "        label_list.append(one_hot_to_char(y[start: end]))\n",
        "    return \"\".join(label_list)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:33.125644Z",
          "iopub.execute_input": "2024-04-05T13:41:33.12607Z",
          "iopub.status.idle": "2024-04-05T13:41:33.134512Z",
          "shell.execute_reply.started": "2024-04-05T13:41:33.126042Z",
          "shell.execute_reply": "2024-04-05T13:41:33.133622Z"
        },
        "trusted": true,
        "id": "3x9p7b6fkhud"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "test_string = \"1abDG\"\n",
        "one_hot(test_string)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:33.135733Z",
          "iopub.execute_input": "2024-04-05T13:41:33.136041Z",
          "iopub.status.idle": "2024-04-05T13:41:33.148791Z",
          "shell.execute_reply.started": "2024-04-05T13:41:33.136017Z",
          "shell.execute_reply": "2024-04-05T13:41:33.147948Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nka2SI8khud",
        "outputId": "f0ef1bc6-31fd-40f8-b329-98aa04dd9600"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "gt_one_hot = [one_hot(i) for i in gt_list]\n",
        "gt_one_hot[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:33.297374Z",
          "iopub.execute_input": "2024-04-05T13:41:33.297983Z",
          "iopub.status.idle": "2024-04-05T13:41:35.925614Z",
          "shell.execute_reply.started": "2024-04-05T13:41:33.297955Z",
          "shell.execute_reply": "2024-04-05T13:41:35.924655Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVwCqLPXkhud",
        "outputId": "f3025ef0-7d9f-428e-fcd2-14b480f71015"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, gt_one_hot, transform=None):\n",
        "        self.images_paths = image_paths\n",
        "        self.gt_list = gt_one_hot\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.images_paths[idx]\n",
        "        image = read_image(image_path).to(torch.float)\n",
        "        label = self.gt_list[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:35.927162Z",
          "iopub.execute_input": "2024-04-05T13:41:35.927479Z",
          "iopub.status.idle": "2024-04-05T13:41:35.933704Z",
          "shell.execute_reply.started": "2024-04-05T13:41:35.927454Z",
          "shell.execute_reply": "2024-04-05T13:41:35.932863Z"
        },
        "trusted": true,
        "id": "1xhk_yjDkhud"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "])\n",
        "\n",
        "datasetTrain = CustomDataset(image_paths[:2*len(image_paths)//3], gt_one_hot[:2*len(gt_one_hot)//3], transform=transform)\n",
        "dataloaderTrain = DataLoader(datasetTrain, batch_size=512, shuffle=True)\n",
        "\n",
        "datasetVal = CustomDataset(image_paths[2*len(image_paths)//3:], gt_one_hot[2*len(gt_one_hot)//3:], transform=transform)\n",
        "dataloaderVal = DataLoader(datasetVal, batch_size=512, shuffle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:35.934761Z",
          "iopub.execute_input": "2024-04-05T13:41:35.935084Z",
          "iopub.status.idle": "2024-04-05T13:41:35.952816Z",
          "shell.execute_reply.started": "2024-04-05T13:41:35.935059Z",
          "shell.execute_reply": "2024-04-05T13:41:35.951847Z"
        },
        "trusted": true,
        "id": "TiswMVG7khue"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "def my_loss_pytorch(y_pred, y_true, CHAR_PER_LABEL=5, NUM_CHAR=60):\n",
        "    tot = 0.0\n",
        "    for i in range(CHAR_PER_LABEL):\n",
        "        start = i * NUM_CHAR\n",
        "        end = start + NUM_CHAR\n",
        "\n",
        "        tot += F.cross_entropy(y_pred[:, start:end], y_true[:, start:end].argmax(dim=1), reduction='sum')\n",
        "    return tot"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:35.954699Z",
          "iopub.execute_input": "2024-04-05T13:41:35.955003Z",
          "iopub.status.idle": "2024-04-05T13:41:35.963498Z",
          "shell.execute_reply.started": "2024-04-05T13:41:35.954979Z",
          "shell.execute_reply": "2024-04-05T13:41:35.962631Z"
        },
        "trusted": true,
        "id": "Zpifk5Trkhue"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalAttention(nn.Module):\n",
        "    def __init__(self, num_channels):\n",
        "        super(GlobalAttention, self).__init__()\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Conv2d(num_channels, 1, kernel_size=1),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attention_weights = self.attention(x)\n",
        "        return x * attention_weights\n",
        "\n",
        "class ModelWithAttention(nn.Module):\n",
        "    def __init__(self, num_characters):\n",
        "        super(ModelWithAttention, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), padding='same')\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3, 3), padding='same')\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=(3, 3), padding='same')\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=(3, 3), padding='same')\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(1, 2))\n",
        "\n",
        "        self.attention = GlobalAttention(512)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(23040, 512)\n",
        "        self.bn5 = nn.BatchNorm1d(512)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.bn6 = nn.BatchNorm1d(512)\n",
        "        self.dropout2 = nn.Dropout(0.75)\n",
        "\n",
        "        self.output = nn.Linear(512, num_characters * 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool2(F.relu(self.bn4(self.conv4(x))))\n",
        "\n",
        "        # apply attention\n",
        "        x = self.attention(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.bn5(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.bn6(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.output(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "D9rZciNPBC9B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ModelWithAttention(60).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-4, amsgrad = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:41:45.776709Z",
          "iopub.execute_input": "2024-04-05T13:41:45.777072Z",
          "iopub.status.idle": "2024-04-05T13:41:46.119314Z",
          "shell.execute_reply.started": "2024-04-05T13:41:45.777043Z",
          "shell.execute_reply": "2024-04-05T13:41:46.118365Z"
        },
        "trusted": true,
        "id": "qxFGZr9ykhue"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "total_time = 0\n",
        "max_epochs = 60\n",
        "val_interval = 1\n",
        "step = 0\n",
        "best_val_loss = float('inf')\n",
        "trainingEpoch_loss = []\n",
        "trainStepsLoss = []\n",
        "validationEpoch_loss = []\n",
        "print_interval = 5\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    model.train()\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "\n",
        "    for batch_data in dataloaderTrain:\n",
        "        step += 1\n",
        "        inputs, labels = batch_data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Normal pipeline\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = my_loss_pytorch(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        if (epoch) % print_interval == 0:\n",
        "            print(f\"{step}/{len(datasetTrain) // dataloaderTrain.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
        "\n",
        "        trainStepsLoss.append(loss.item())\n",
        "\n",
        "    epoch_loss /= step\n",
        "    trainingEpoch_loss.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "    if epoch % val_interval == 0:\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_steps = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_data in dataloaderVal:\n",
        "                inputs, labels = batch_data\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = my_loss_pytorch(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                val_steps += 1\n",
        "\n",
        "        average_val_loss = val_loss / val_steps\n",
        "        validationEpoch_loss.append(average_val_loss)\n",
        "        if average_val_loss < best_val_loss:\n",
        "            best_val_loss = average_val_loss\n",
        "            torch.save(model.state_dict(), 'model_best.pth')\n",
        "            print(f\"Epoch {epoch}: New best model saved with val_loss: {average_val_loss}\")\n",
        "\n",
        "\n",
        "        print(f'Epoch {epoch}: Average validation loss = {average_val_loss}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:48:17.132831Z",
          "iopub.execute_input": "2024-04-05T13:48:17.133562Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqarZ0n2khue",
        "outputId": "ab75584b-a02f-42ae-c67c-5ab80a1d3e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "epoch 1/60\n",
            "1/147, train_loss: 11393.5762\n",
            "2/147, train_loss: 11312.3223\n",
            "3/147, train_loss: 11322.2578\n",
            "4/147, train_loss: 11274.5723\n",
            "5/147, train_loss: 11240.8760\n",
            "6/147, train_loss: 11215.4111\n",
            "7/147, train_loss: 11203.8906\n",
            "8/147, train_loss: 11147.9707\n",
            "9/147, train_loss: 11177.2617\n",
            "10/147, train_loss: 11165.9502\n",
            "11/147, train_loss: 11194.6953\n",
            "12/147, train_loss: 11205.0303\n",
            "13/147, train_loss: 11155.5195\n",
            "14/147, train_loss: 11188.8164\n",
            "15/147, train_loss: 11113.2012\n",
            "16/147, train_loss: 11087.9492\n",
            "17/147, train_loss: 11115.5947\n",
            "18/147, train_loss: 11152.5430\n",
            "19/147, train_loss: 11081.4092\n",
            "20/147, train_loss: 11024.8379\n",
            "21/147, train_loss: 11127.1924\n",
            "22/147, train_loss: 11081.0322\n",
            "23/147, train_loss: 11068.4922\n",
            "24/147, train_loss: 11003.3223\n",
            "25/147, train_loss: 11007.9492\n",
            "26/147, train_loss: 11034.9609\n",
            "27/147, train_loss: 10991.3643\n",
            "28/147, train_loss: 10935.9824\n",
            "29/147, train_loss: 10974.9023\n",
            "30/147, train_loss: 11011.9648\n",
            "31/147, train_loss: 10966.1016\n",
            "32/147, train_loss: 10912.2441\n",
            "33/147, train_loss: 10865.0137\n",
            "34/147, train_loss: 10922.7432\n",
            "35/147, train_loss: 10947.6709\n",
            "36/147, train_loss: 10940.8477\n",
            "37/147, train_loss: 10997.2148\n",
            "38/147, train_loss: 10923.1475\n",
            "39/147, train_loss: 10950.9414\n",
            "40/147, train_loss: 10862.1201\n",
            "41/147, train_loss: 10880.6807\n",
            "42/147, train_loss: 10867.2881\n",
            "43/147, train_loss: 10868.3516\n",
            "44/147, train_loss: 10835.8281\n",
            "45/147, train_loss: 10849.8818\n",
            "46/147, train_loss: 10776.7070\n",
            "47/147, train_loss: 10883.3555\n",
            "48/147, train_loss: 10815.9619\n",
            "49/147, train_loss: 10790.8555\n",
            "50/147, train_loss: 10809.8418\n",
            "51/147, train_loss: 10844.7549\n",
            "52/147, train_loss: 10778.1523\n",
            "53/147, train_loss: 10689.4219\n",
            "54/147, train_loss: 10812.4668\n",
            "55/147, train_loss: 10782.6426\n",
            "56/147, train_loss: 10811.9424\n",
            "57/147, train_loss: 10716.6523\n",
            "58/147, train_loss: 10765.1270\n",
            "59/147, train_loss: 10754.3525\n",
            "60/147, train_loss: 10723.0264\n",
            "61/147, train_loss: 10725.4219\n",
            "62/147, train_loss: 10722.4082\n",
            "63/147, train_loss: 10705.9189\n",
            "64/147, train_loss: 10709.8496\n",
            "65/147, train_loss: 10665.8926\n",
            "66/147, train_loss: 10729.0703\n",
            "67/147, train_loss: 10685.6875\n",
            "68/147, train_loss: 10626.6260\n",
            "69/147, train_loss: 10644.8652\n",
            "70/147, train_loss: 10665.3320\n",
            "71/147, train_loss: 10704.8789\n",
            "72/147, train_loss: 10689.1367\n",
            "73/147, train_loss: 10700.0547\n",
            "74/147, train_loss: 10640.3086\n",
            "75/147, train_loss: 10633.0127\n",
            "76/147, train_loss: 10633.4375\n",
            "77/147, train_loss: 10679.7676\n",
            "78/147, train_loss: 10638.0117\n",
            "79/147, train_loss: 10577.2354\n",
            "80/147, train_loss: 10677.0029\n",
            "81/147, train_loss: 10652.8008\n",
            "82/147, train_loss: 10629.7012\n",
            "83/147, train_loss: 10594.1045\n",
            "84/147, train_loss: 10593.2832\n",
            "85/147, train_loss: 10554.3105\n",
            "86/147, train_loss: 10606.7676\n",
            "87/147, train_loss: 10581.4785\n",
            "88/147, train_loss: 10638.9062\n",
            "89/147, train_loss: 10596.9590\n",
            "90/147, train_loss: 10574.5791\n",
            "91/147, train_loss: 10602.1309\n",
            "92/147, train_loss: 10584.2246\n",
            "93/147, train_loss: 10580.5576\n",
            "94/147, train_loss: 10610.8740\n",
            "95/147, train_loss: 10566.7422\n",
            "96/147, train_loss: 10577.9639\n",
            "97/147, train_loss: 10573.9902\n",
            "98/147, train_loss: 10572.5742\n",
            "99/147, train_loss: 10512.1973\n",
            "100/147, train_loss: 10539.8047\n",
            "101/147, train_loss: 10547.8652\n",
            "102/147, train_loss: 10542.3096\n",
            "103/147, train_loss: 10578.8594\n",
            "104/147, train_loss: 10592.7539\n",
            "105/147, train_loss: 10589.7500\n",
            "106/147, train_loss: 10540.3730\n",
            "107/147, train_loss: 10549.6094\n",
            "108/147, train_loss: 10539.5527\n",
            "109/147, train_loss: 10563.9990\n",
            "110/147, train_loss: 10495.1660\n",
            "111/147, train_loss: 10544.5420\n",
            "112/147, train_loss: 10488.2324\n",
            "113/147, train_loss: 10570.1562\n",
            "114/147, train_loss: 10534.4453\n",
            "115/147, train_loss: 10498.4258\n",
            "116/147, train_loss: 10498.8828\n",
            "117/147, train_loss: 10509.1113\n",
            "118/147, train_loss: 10538.8828\n",
            "119/147, train_loss: 10531.0859\n",
            "120/147, train_loss: 10495.4844\n",
            "121/147, train_loss: 10514.3066\n",
            "122/147, train_loss: 10519.0967\n",
            "123/147, train_loss: 10447.5938\n",
            "124/147, train_loss: 10531.8906\n",
            "125/147, train_loss: 10502.8281\n",
            "126/147, train_loss: 10502.6504\n",
            "127/147, train_loss: 10519.8633\n",
            "128/147, train_loss: 10482.0918\n",
            "129/147, train_loss: 10494.2207\n",
            "130/147, train_loss: 10462.5039\n",
            "131/147, train_loss: 10501.9092\n",
            "132/147, train_loss: 10484.2412\n",
            "133/147, train_loss: 10501.4961\n",
            "134/147, train_loss: 10506.5723\n",
            "135/147, train_loss: 10482.1699\n",
            "136/147, train_loss: 10454.6699\n",
            "137/147, train_loss: 10489.9219\n",
            "138/147, train_loss: 10500.0107\n",
            "139/147, train_loss: 10485.2344\n",
            "140/147, train_loss: 10495.8281\n",
            "141/147, train_loss: 10478.6309\n",
            "142/147, train_loss: 10447.5020\n",
            "143/147, train_loss: 10501.5469\n",
            "144/147, train_loss: 10482.3125\n",
            "145/147, train_loss: 10503.1494\n",
            "146/147, train_loss: 10468.8350\n",
            "147/147, train_loss: 10470.0518\n",
            "148/147, train_loss: 2261.4360\n",
            "epoch 1 average loss: 10681.0548\n",
            "Epoch 0: New best model saved with val_loss: 10952.51720201647\n",
            "Epoch 0: Average validation loss = 10952.51720201647\n",
            "----------\n",
            "epoch 2/60\n",
            "epoch 2 average loss: 10314.2450\n",
            "Epoch 1: Average validation loss = 11251.325769372888\n",
            "----------\n",
            "epoch 3/60\n",
            "epoch 3 average loss: 9999.0958\n",
            "Epoch 2: Average validation loss = 11937.691287478885\n",
            "----------\n",
            "epoch 4/60\n",
            "epoch 4 average loss: 9483.1564\n",
            "Epoch 3: Average validation loss = 11237.859711518158\n",
            "----------\n",
            "epoch 5/60\n",
            "epoch 5 average loss: 8915.4476\n",
            "Epoch 4: Average validation loss = 11044.290250211148\n",
            "----------\n",
            "epoch 6/60\n",
            "1/147, train_loss: 8653.6123\n",
            "2/147, train_loss: 8559.1240\n",
            "3/147, train_loss: 8636.9932\n",
            "4/147, train_loss: 8632.8516\n",
            "5/147, train_loss: 8709.3691\n",
            "6/147, train_loss: 8678.8535\n",
            "7/147, train_loss: 8699.7354\n",
            "8/147, train_loss: 8633.9180\n",
            "9/147, train_loss: 8714.2793\n",
            "10/147, train_loss: 8617.8682\n",
            "11/147, train_loss: 8624.2090\n",
            "12/147, train_loss: 8635.0342\n",
            "13/147, train_loss: 8624.7139\n",
            "14/147, train_loss: 8626.8584\n",
            "15/147, train_loss: 8661.1543\n",
            "16/147, train_loss: 8640.2119\n",
            "17/147, train_loss: 8619.5361\n",
            "18/147, train_loss: 8611.5684\n",
            "19/147, train_loss: 8637.3604\n",
            "20/147, train_loss: 8685.7832\n",
            "21/147, train_loss: 8592.2383\n",
            "22/147, train_loss: 8522.3340\n",
            "23/147, train_loss: 8547.8779\n",
            "24/147, train_loss: 8627.2383\n",
            "25/147, train_loss: 8653.7080\n",
            "26/147, train_loss: 8725.9561\n",
            "27/147, train_loss: 8612.9922\n",
            "28/147, train_loss: 8582.2676\n",
            "29/147, train_loss: 8656.7285\n",
            "30/147, train_loss: 8599.4795\n",
            "31/147, train_loss: 8651.0605\n",
            "32/147, train_loss: 8572.6387\n",
            "33/147, train_loss: 8586.6123\n",
            "34/147, train_loss: 8613.8389\n",
            "35/147, train_loss: 8570.4268\n",
            "36/147, train_loss: 8514.0684\n",
            "37/147, train_loss: 8561.1025\n",
            "38/147, train_loss: 8586.1992\n",
            "39/147, train_loss: 8504.7656\n",
            "40/147, train_loss: 8535.2188\n",
            "41/147, train_loss: 8588.2324\n",
            "42/147, train_loss: 8635.5703\n",
            "43/147, train_loss: 8559.8281\n",
            "44/147, train_loss: 8588.7285\n",
            "45/147, train_loss: 8607.4150\n",
            "46/147, train_loss: 8604.9834\n",
            "47/147, train_loss: 8569.0957\n",
            "48/147, train_loss: 8481.7627\n",
            "49/147, train_loss: 8569.9248\n",
            "50/147, train_loss: 8537.7275\n",
            "51/147, train_loss: 8532.8613\n",
            "52/147, train_loss: 8587.0215\n",
            "53/147, train_loss: 8504.1299\n",
            "54/147, train_loss: 8517.4932\n",
            "55/147, train_loss: 8521.5576\n",
            "56/147, train_loss: 8534.7568\n",
            "57/147, train_loss: 8522.4062\n",
            "58/147, train_loss: 8473.6572\n",
            "59/147, train_loss: 8527.4238\n",
            "60/147, train_loss: 8512.6465\n",
            "61/147, train_loss: 8543.4014\n",
            "62/147, train_loss: 8473.5195\n",
            "63/147, train_loss: 8525.8311\n",
            "64/147, train_loss: 8572.3115\n",
            "65/147, train_loss: 8487.6318\n",
            "66/147, train_loss: 8452.7676\n",
            "67/147, train_loss: 8478.0850\n",
            "68/147, train_loss: 8482.6973\n",
            "69/147, train_loss: 8554.0654\n",
            "70/147, train_loss: 8542.7910\n",
            "71/147, train_loss: 8576.7979\n",
            "72/147, train_loss: 8518.2168\n",
            "73/147, train_loss: 8518.6982\n",
            "74/147, train_loss: 8473.9375\n",
            "75/147, train_loss: 8529.0625\n",
            "76/147, train_loss: 8538.6074\n",
            "77/147, train_loss: 8465.9326\n",
            "78/147, train_loss: 8489.8291\n",
            "79/147, train_loss: 8436.9004\n",
            "80/147, train_loss: 8547.0312\n",
            "81/147, train_loss: 8539.7031\n",
            "82/147, train_loss: 8478.9365\n",
            "83/147, train_loss: 8475.4014\n",
            "84/147, train_loss: 8446.1250\n",
            "85/147, train_loss: 8481.3145\n",
            "86/147, train_loss: 8427.1777\n",
            "87/147, train_loss: 8500.8457\n",
            "88/147, train_loss: 8416.4844\n",
            "89/147, train_loss: 8458.3789\n",
            "90/147, train_loss: 8481.8887\n",
            "91/147, train_loss: 8534.0811\n",
            "92/147, train_loss: 8421.0254\n",
            "93/147, train_loss: 8450.2344\n",
            "94/147, train_loss: 8477.0078\n",
            "95/147, train_loss: 8438.6387\n",
            "96/147, train_loss: 8369.9385\n",
            "97/147, train_loss: 8447.3262\n",
            "98/147, train_loss: 8444.0674\n",
            "99/147, train_loss: 8363.3887\n",
            "100/147, train_loss: 8402.3320\n",
            "101/147, train_loss: 8414.7051\n",
            "102/147, train_loss: 8381.2100\n",
            "103/147, train_loss: 8447.2207\n",
            "104/147, train_loss: 8374.2637\n",
            "105/147, train_loss: 8373.8398\n",
            "106/147, train_loss: 8417.9922\n",
            "107/147, train_loss: 8392.3057\n",
            "108/147, train_loss: 8494.9805\n",
            "109/147, train_loss: 8377.7295\n",
            "110/147, train_loss: 8372.7393\n",
            "111/147, train_loss: 8402.6074\n",
            "112/147, train_loss: 8411.6914\n",
            "113/147, train_loss: 8358.2979\n",
            "114/147, train_loss: 8301.6270\n",
            "115/147, train_loss: 8332.6094\n",
            "116/147, train_loss: 8400.8672\n",
            "117/147, train_loss: 8384.8672\n",
            "118/147, train_loss: 8392.6846\n",
            "119/147, train_loss: 8413.0586\n",
            "120/147, train_loss: 8330.0547\n",
            "121/147, train_loss: 8383.9697\n",
            "122/147, train_loss: 8332.8203\n",
            "123/147, train_loss: 8418.9893\n",
            "124/147, train_loss: 8441.8848\n",
            "125/147, train_loss: 8323.7324\n",
            "126/147, train_loss: 8323.5312\n",
            "127/147, train_loss: 8352.2930\n",
            "128/147, train_loss: 8306.4590\n",
            "129/147, train_loss: 8396.2686\n",
            "130/147, train_loss: 8340.9336\n",
            "131/147, train_loss: 8327.9014\n",
            "132/147, train_loss: 8417.5107\n",
            "133/147, train_loss: 8332.0859\n",
            "134/147, train_loss: 8400.8838\n",
            "135/147, train_loss: 8336.4180\n",
            "136/147, train_loss: 8364.4990\n",
            "137/147, train_loss: 8370.1055\n",
            "138/147, train_loss: 8336.7471\n",
            "139/147, train_loss: 8354.7090\n",
            "140/147, train_loss: 8335.5127\n",
            "141/147, train_loss: 8355.2852\n",
            "142/147, train_loss: 8284.9209\n",
            "143/147, train_loss: 8274.6924\n",
            "144/147, train_loss: 8238.8828\n",
            "145/147, train_loss: 8262.9639\n",
            "146/147, train_loss: 8312.6533\n",
            "147/147, train_loss: 8311.2988\n",
            "148/147, train_loss: 1754.5837\n",
            "epoch 6 average loss: 8444.1034\n",
            "Epoch 5: Average validation loss = 10981.95899757179\n",
            "----------\n",
            "epoch 7/60\n",
            "epoch 7 average loss: 8042.6171\n",
            "Epoch 6: New best model saved with val_loss: 10668.631387246622\n",
            "Epoch 6: Average validation loss = 10668.631387246622\n",
            "----------\n",
            "epoch 8/60\n",
            "epoch 8 average loss: 7694.5158\n",
            "Epoch 7: New best model saved with val_loss: 10494.764437288852\n",
            "Epoch 7: Average validation loss = 10494.764437288852\n",
            "----------\n",
            "epoch 9/60\n",
            "epoch 9 average loss: 7380.2464\n",
            "Epoch 8: New best model saved with val_loss: 10385.621001372467\n",
            "Epoch 8: Average validation loss = 10385.621001372467\n",
            "----------\n",
            "epoch 10/60\n",
            "epoch 10 average loss: 7095.4869\n",
            "Epoch 9: New best model saved with val_loss: 10242.456707928632\n",
            "Epoch 9: Average validation loss = 10242.456707928632\n",
            "----------\n",
            "epoch 11/60\n",
            "1/147, train_loss: 6968.6733\n",
            "2/147, train_loss: 7047.9604\n",
            "3/147, train_loss: 6971.6348\n",
            "4/147, train_loss: 6870.7480\n",
            "5/147, train_loss: 6883.4473\n",
            "6/147, train_loss: 6922.4971\n",
            "7/147, train_loss: 7009.4893\n",
            "8/147, train_loss: 6994.9395\n",
            "9/147, train_loss: 6954.6055\n",
            "10/147, train_loss: 6871.3271\n",
            "11/147, train_loss: 6989.0947\n",
            "12/147, train_loss: 7005.6821\n",
            "13/147, train_loss: 6985.4463\n",
            "14/147, train_loss: 6880.5225\n",
            "15/147, train_loss: 6924.4805\n",
            "16/147, train_loss: 6978.2510\n",
            "17/147, train_loss: 7014.9536\n",
            "18/147, train_loss: 6873.3354\n",
            "19/147, train_loss: 6960.9458\n",
            "20/147, train_loss: 6885.3657\n",
            "21/147, train_loss: 6931.5527\n",
            "22/147, train_loss: 6920.2930\n",
            "23/147, train_loss: 6912.0479\n",
            "24/147, train_loss: 6954.0132\n",
            "25/147, train_loss: 6987.1680\n",
            "26/147, train_loss: 6927.2749\n",
            "27/147, train_loss: 6962.8594\n",
            "28/147, train_loss: 6976.0566\n",
            "29/147, train_loss: 6898.6670\n",
            "30/147, train_loss: 7018.3594\n",
            "31/147, train_loss: 6898.0864\n",
            "32/147, train_loss: 6988.7295\n",
            "33/147, train_loss: 6866.3921\n",
            "34/147, train_loss: 6857.0581\n",
            "35/147, train_loss: 6903.8892\n",
            "36/147, train_loss: 6849.6943\n",
            "37/147, train_loss: 6976.9688\n",
            "38/147, train_loss: 6933.2456\n",
            "39/147, train_loss: 6990.0586\n",
            "40/147, train_loss: 6830.1558\n",
            "41/147, train_loss: 6935.8252\n",
            "42/147, train_loss: 6912.0557\n",
            "43/147, train_loss: 6886.9351\n",
            "44/147, train_loss: 6871.5254\n",
            "45/147, train_loss: 6960.5020\n",
            "46/147, train_loss: 6901.5894\n",
            "47/147, train_loss: 6957.6167\n",
            "48/147, train_loss: 6874.2461\n",
            "49/147, train_loss: 6888.7671\n",
            "50/147, train_loss: 6947.3218\n",
            "51/147, train_loss: 6887.4858\n",
            "52/147, train_loss: 6837.3818\n",
            "53/147, train_loss: 6897.4639\n",
            "54/147, train_loss: 6838.6108\n",
            "55/147, train_loss: 6889.0649\n",
            "56/147, train_loss: 6938.2529\n",
            "57/147, train_loss: 6861.7471\n",
            "58/147, train_loss: 6830.8008\n",
            "59/147, train_loss: 6937.2344\n",
            "60/147, train_loss: 7007.4907\n",
            "61/147, train_loss: 6992.2217\n",
            "62/147, train_loss: 6971.7622\n",
            "63/147, train_loss: 7022.1577\n",
            "64/147, train_loss: 6948.2188\n",
            "65/147, train_loss: 6974.8901\n",
            "66/147, train_loss: 6896.8286\n",
            "67/147, train_loss: 6919.1997\n",
            "68/147, train_loss: 6858.0674\n",
            "69/147, train_loss: 6933.7705\n",
            "70/147, train_loss: 6851.0728\n",
            "71/147, train_loss: 6886.6313\n",
            "72/147, train_loss: 6838.8506\n",
            "73/147, train_loss: 6904.7129\n",
            "74/147, train_loss: 6805.6470\n",
            "75/147, train_loss: 6908.1152\n",
            "76/147, train_loss: 6910.4238\n",
            "77/147, train_loss: 6927.6387\n",
            "78/147, train_loss: 6897.5664\n",
            "79/147, train_loss: 6888.4312\n",
            "80/147, train_loss: 6862.3906\n",
            "81/147, train_loss: 6864.5576\n",
            "82/147, train_loss: 6906.3267\n",
            "83/147, train_loss: 6896.5127\n",
            "84/147, train_loss: 6884.3438\n",
            "85/147, train_loss: 6899.9028\n",
            "86/147, train_loss: 6894.4316\n",
            "87/147, train_loss: 6926.6670\n",
            "88/147, train_loss: 6928.0054\n",
            "89/147, train_loss: 6864.3770\n",
            "90/147, train_loss: 6873.4565\n",
            "91/147, train_loss: 6829.0063\n",
            "92/147, train_loss: 6934.0488\n",
            "93/147, train_loss: 6862.9873\n",
            "94/147, train_loss: 6884.6592\n",
            "95/147, train_loss: 6970.1680\n",
            "96/147, train_loss: 6864.0449\n",
            "97/147, train_loss: 6905.6255\n",
            "98/147, train_loss: 6860.1558\n",
            "99/147, train_loss: 6841.6963\n",
            "100/147, train_loss: 6802.4238\n",
            "101/147, train_loss: 6838.3896\n",
            "102/147, train_loss: 6817.0112\n",
            "103/147, train_loss: 6881.2539\n",
            "104/147, train_loss: 6827.0039\n",
            "105/147, train_loss: 6844.1230\n",
            "106/147, train_loss: 6806.5820\n",
            "107/147, train_loss: 6943.0127\n",
            "108/147, train_loss: 6833.4004\n",
            "109/147, train_loss: 6789.8350\n",
            "110/147, train_loss: 6834.0029\n",
            "111/147, train_loss: 6842.2539\n",
            "112/147, train_loss: 6833.9668\n",
            "113/147, train_loss: 6923.8213\n",
            "114/147, train_loss: 6799.3179\n",
            "115/147, train_loss: 6953.7593\n",
            "116/147, train_loss: 6895.2266\n",
            "117/147, train_loss: 6908.3579\n",
            "118/147, train_loss: 6804.6333\n",
            "119/147, train_loss: 6764.4941\n",
            "120/147, train_loss: 6881.8755\n",
            "121/147, train_loss: 6854.0322\n",
            "122/147, train_loss: 6810.1592\n",
            "123/147, train_loss: 6795.4277\n",
            "124/147, train_loss: 6846.8027\n",
            "125/147, train_loss: 6819.9814\n",
            "126/147, train_loss: 6860.6045\n",
            "127/147, train_loss: 6844.4575\n",
            "128/147, train_loss: 6765.3179\n",
            "129/147, train_loss: 6854.0083\n",
            "130/147, train_loss: 6843.7949\n",
            "131/147, train_loss: 6926.7529\n",
            "132/147, train_loss: 6729.4438\n",
            "133/147, train_loss: 6730.3848\n",
            "134/147, train_loss: 6784.5771\n",
            "135/147, train_loss: 6796.8403\n",
            "136/147, train_loss: 6805.5879\n",
            "137/147, train_loss: 6888.7583\n",
            "138/147, train_loss: 6823.2480\n",
            "139/147, train_loss: 6827.2480\n",
            "140/147, train_loss: 6793.5366\n",
            "141/147, train_loss: 6750.7520\n",
            "142/147, train_loss: 6802.7124\n",
            "143/147, train_loss: 6857.8594\n",
            "144/147, train_loss: 6839.9829\n",
            "145/147, train_loss: 6775.2109\n",
            "146/147, train_loss: 6823.3311\n",
            "147/147, train_loss: 6826.0000\n",
            "148/147, train_loss: 1447.2565\n",
            "epoch 11 average loss: 6851.8667\n",
            "Epoch 10: New best model saved with val_loss: 10182.160565350507\n",
            "Epoch 10: Average validation loss = 10182.160565350507\n",
            "----------\n",
            "epoch 12/60\n",
            "epoch 12 average loss: 6614.4801\n",
            "Epoch 11: New best model saved with val_loss: 9994.552925728463\n",
            "Epoch 11: Average validation loss = 9994.552925728463\n",
            "----------\n",
            "epoch 13/60\n",
            "epoch 13 average loss: 6405.3786\n",
            "Epoch 12: New best model saved with val_loss: 9923.593182538007\n",
            "Epoch 12: Average validation loss = 9923.593182538007\n",
            "----------\n",
            "epoch 14/60\n",
            "epoch 14 average loss: 6221.1090\n",
            "Epoch 13: New best model saved with val_loss: 9816.286185599662\n",
            "Epoch 13: Average validation loss = 9816.286185599662\n",
            "----------\n",
            "epoch 15/60\n",
            "epoch 15 average loss: 6045.2699\n",
            "Epoch 14: New best model saved with val_loss: 9785.293305268158\n",
            "Epoch 14: Average validation loss = 9785.293305268158\n",
            "----------\n",
            "epoch 16/60\n",
            "1/147, train_loss: 6047.2173\n",
            "2/147, train_loss: 6014.5498\n",
            "3/147, train_loss: 5956.8423\n",
            "4/147, train_loss: 5901.1924\n",
            "5/147, train_loss: 6030.4404\n",
            "6/147, train_loss: 5901.9668\n",
            "7/147, train_loss: 6017.7012\n",
            "8/147, train_loss: 5977.2095\n",
            "9/147, train_loss: 5966.5586\n",
            "10/147, train_loss: 5935.5288\n",
            "11/147, train_loss: 5962.6416\n",
            "12/147, train_loss: 6017.5571\n",
            "13/147, train_loss: 5949.2983\n",
            "14/147, train_loss: 5912.1113\n",
            "15/147, train_loss: 5965.3521\n",
            "16/147, train_loss: 6003.5200\n",
            "17/147, train_loss: 5915.2065\n",
            "18/147, train_loss: 5868.2554\n",
            "19/147, train_loss: 5972.3535\n",
            "20/147, train_loss: 5995.3398\n",
            "21/147, train_loss: 5941.0371\n",
            "22/147, train_loss: 5954.5840\n",
            "23/147, train_loss: 5941.1768\n",
            "24/147, train_loss: 5905.9385\n",
            "25/147, train_loss: 5956.0225\n",
            "26/147, train_loss: 5977.1099\n",
            "27/147, train_loss: 5958.2744\n",
            "28/147, train_loss: 5835.3145\n",
            "29/147, train_loss: 5945.3335\n",
            "30/147, train_loss: 6016.7764\n",
            "31/147, train_loss: 5958.9746\n",
            "32/147, train_loss: 5890.5439\n",
            "33/147, train_loss: 5887.0762\n",
            "34/147, train_loss: 5865.0640\n",
            "35/147, train_loss: 6032.6558\n",
            "36/147, train_loss: 5948.9937\n",
            "37/147, train_loss: 5904.1860\n",
            "38/147, train_loss: 5940.8350\n",
            "39/147, train_loss: 5916.6602\n",
            "40/147, train_loss: 6005.2690\n",
            "41/147, train_loss: 5867.7666\n",
            "42/147, train_loss: 5932.3486\n",
            "43/147, train_loss: 6011.1895\n",
            "44/147, train_loss: 5974.0332\n",
            "45/147, train_loss: 5863.3730\n",
            "46/147, train_loss: 5903.1631\n",
            "47/147, train_loss: 5882.4561\n",
            "48/147, train_loss: 5931.2544\n",
            "49/147, train_loss: 5947.3257\n",
            "50/147, train_loss: 5962.9351\n",
            "51/147, train_loss: 5929.1040\n",
            "52/147, train_loss: 5878.9165\n",
            "53/147, train_loss: 5940.3652\n",
            "54/147, train_loss: 5884.3394\n",
            "55/147, train_loss: 5923.5679\n",
            "56/147, train_loss: 6018.0166\n",
            "57/147, train_loss: 5974.8521\n",
            "58/147, train_loss: 6051.4980\n",
            "59/147, train_loss: 6014.9683\n",
            "60/147, train_loss: 5869.0234\n",
            "61/147, train_loss: 5966.1548\n",
            "62/147, train_loss: 5903.9048\n",
            "63/147, train_loss: 5952.9985\n",
            "64/147, train_loss: 5988.6533\n",
            "65/147, train_loss: 5960.0947\n",
            "66/147, train_loss: 5890.6836\n",
            "67/147, train_loss: 5944.9814\n",
            "68/147, train_loss: 5857.1997\n",
            "69/147, train_loss: 5853.4180\n",
            "70/147, train_loss: 5916.3857\n",
            "71/147, train_loss: 5824.3369\n",
            "72/147, train_loss: 5921.8433\n",
            "73/147, train_loss: 5858.6768\n",
            "74/147, train_loss: 5969.4795\n",
            "75/147, train_loss: 5908.5718\n",
            "76/147, train_loss: 5984.8262\n",
            "77/147, train_loss: 5929.9790\n",
            "78/147, train_loss: 5937.5532\n",
            "79/147, train_loss: 5916.9473\n",
            "80/147, train_loss: 5940.8750\n",
            "81/147, train_loss: 5967.7515\n",
            "82/147, train_loss: 5919.2217\n",
            "83/147, train_loss: 5872.6787\n",
            "84/147, train_loss: 5875.1963\n",
            "85/147, train_loss: 5967.6821\n",
            "86/147, train_loss: 5867.9717\n",
            "87/147, train_loss: 5943.8359\n",
            "88/147, train_loss: 5915.8154\n",
            "89/147, train_loss: 5904.6470\n",
            "90/147, train_loss: 5981.5884\n",
            "91/147, train_loss: 5886.4487\n",
            "92/147, train_loss: 5957.6665\n",
            "93/147, train_loss: 5914.8374\n",
            "94/147, train_loss: 5896.1084\n",
            "95/147, train_loss: 5931.5283\n",
            "96/147, train_loss: 5828.8281\n",
            "97/147, train_loss: 6010.1592\n",
            "98/147, train_loss: 5952.8096\n",
            "99/147, train_loss: 5916.6431\n",
            "100/147, train_loss: 5950.4336\n",
            "101/147, train_loss: 5959.5088\n",
            "102/147, train_loss: 5891.6924\n",
            "103/147, train_loss: 5940.5181\n",
            "104/147, train_loss: 5919.8760\n",
            "105/147, train_loss: 5989.1665\n",
            "106/147, train_loss: 5869.7461\n",
            "107/147, train_loss: 5854.7266\n",
            "108/147, train_loss: 5777.2222\n",
            "109/147, train_loss: 5971.9873\n",
            "110/147, train_loss: 5912.1523\n",
            "111/147, train_loss: 5888.8813\n",
            "112/147, train_loss: 5919.9141\n",
            "113/147, train_loss: 5922.6099\n",
            "114/147, train_loss: 5868.6792\n",
            "115/147, train_loss: 5848.4043\n",
            "116/147, train_loss: 5787.0591\n",
            "117/147, train_loss: 5883.8408\n",
            "118/147, train_loss: 5930.2803\n",
            "119/147, train_loss: 5819.8130\n",
            "120/147, train_loss: 5954.9883\n",
            "121/147, train_loss: 5849.1650\n",
            "122/147, train_loss: 5973.9287\n",
            "123/147, train_loss: 5842.3389\n",
            "124/147, train_loss: 5882.0137\n",
            "125/147, train_loss: 5936.0195\n",
            "126/147, train_loss: 5892.7651\n",
            "127/147, train_loss: 5917.4297\n",
            "128/147, train_loss: 5846.4736\n",
            "129/147, train_loss: 5937.3394\n",
            "130/147, train_loss: 5849.8589\n",
            "131/147, train_loss: 5916.9912\n",
            "132/147, train_loss: 5896.7114\n",
            "133/147, train_loss: 5932.7168\n",
            "134/147, train_loss: 5882.6973\n",
            "135/147, train_loss: 5865.8213\n",
            "136/147, train_loss: 5921.2803\n",
            "137/147, train_loss: 5961.2456\n",
            "138/147, train_loss: 5956.9697\n",
            "139/147, train_loss: 6038.6416\n",
            "140/147, train_loss: 5907.6157\n",
            "141/147, train_loss: 5813.2212\n",
            "142/147, train_loss: 5951.2891\n",
            "143/147, train_loss: 5899.7383\n",
            "144/147, train_loss: 5887.6738\n",
            "145/147, train_loss: 5891.9375\n",
            "146/147, train_loss: 5865.6729\n",
            "147/147, train_loss: 5911.7437\n",
            "148/147, train_loss: 1307.2551\n",
            "epoch 16 average loss: 5894.5284\n",
            "Epoch 15: New best model saved with val_loss: 9718.839764569257\n",
            "Epoch 15: Average validation loss = 9718.839764569257\n",
            "----------\n",
            "epoch 17/60\n",
            "epoch 17 average loss: 5743.9879\n",
            "Epoch 16: New best model saved with val_loss: 9598.281817461993\n",
            "Epoch 16: Average validation loss = 9598.281817461993\n",
            "----------\n",
            "epoch 18/60\n",
            "epoch 18 average loss: 5609.1212\n",
            "Epoch 17: New best model saved with val_loss: 9528.278663429053\n",
            "Epoch 17: Average validation loss = 9528.278663429053\n",
            "----------\n",
            "epoch 19/60\n",
            "epoch 19 average loss: 5490.8538\n",
            "Epoch 18: Average validation loss = 9568.733728357263\n",
            "----------\n",
            "epoch 20/60\n",
            "epoch 20 average loss: 5372.1257\n",
            "Epoch 19: Average validation loss = 9544.194969383447\n",
            "----------\n",
            "epoch 21/60\n",
            "1/147, train_loss: 5298.0640\n",
            "2/147, train_loss: 5338.5820\n",
            "3/147, train_loss: 5300.5713\n",
            "4/147, train_loss: 5301.1226\n",
            "5/147, train_loss: 5332.5166\n",
            "6/147, train_loss: 5287.6899\n",
            "7/147, train_loss: 5266.4512\n",
            "8/147, train_loss: 5315.6108\n",
            "9/147, train_loss: 5317.6851\n",
            "10/147, train_loss: 5301.8120\n",
            "11/147, train_loss: 5309.0552\n",
            "12/147, train_loss: 5348.3906\n",
            "13/147, train_loss: 5285.8350\n",
            "14/147, train_loss: 5363.7607\n",
            "15/147, train_loss: 5290.0015\n",
            "16/147, train_loss: 5316.7026\n",
            "17/147, train_loss: 5238.5474\n",
            "18/147, train_loss: 5300.7100\n",
            "19/147, train_loss: 5287.5942\n",
            "20/147, train_loss: 5245.6479\n",
            "21/147, train_loss: 5360.6826\n",
            "22/147, train_loss: 5197.8730\n",
            "23/147, train_loss: 5248.6343\n",
            "24/147, train_loss: 5310.0303\n",
            "25/147, train_loss: 5367.7363\n",
            "26/147, train_loss: 5381.8594\n",
            "27/147, train_loss: 5298.6064\n",
            "28/147, train_loss: 5279.9268\n",
            "29/147, train_loss: 5374.1299\n",
            "30/147, train_loss: 5391.8066\n",
            "31/147, train_loss: 5294.6079\n",
            "32/147, train_loss: 5280.7148\n",
            "33/147, train_loss: 5271.2612\n",
            "34/147, train_loss: 5260.9326\n",
            "35/147, train_loss: 5383.2612\n",
            "36/147, train_loss: 5312.8975\n",
            "37/147, train_loss: 5288.5278\n",
            "38/147, train_loss: 5308.5195\n",
            "39/147, train_loss: 5266.3823\n",
            "40/147, train_loss: 5307.3872\n",
            "41/147, train_loss: 5289.5977\n",
            "42/147, train_loss: 5259.3857\n",
            "43/147, train_loss: 5352.8223\n",
            "44/147, train_loss: 5301.4346\n",
            "45/147, train_loss: 5287.7598\n",
            "46/147, train_loss: 5312.6631\n",
            "47/147, train_loss: 5369.4692\n",
            "48/147, train_loss: 5287.1104\n",
            "49/147, train_loss: 5350.1626\n",
            "50/147, train_loss: 5194.5654\n",
            "51/147, train_loss: 5265.6636\n",
            "52/147, train_loss: 5376.8301\n",
            "53/147, train_loss: 5218.5103\n",
            "54/147, train_loss: 5289.0527\n",
            "55/147, train_loss: 5284.4756\n",
            "56/147, train_loss: 5307.0352\n",
            "57/147, train_loss: 5296.0391\n",
            "58/147, train_loss: 5283.4541\n",
            "59/147, train_loss: 5277.1543\n",
            "60/147, train_loss: 5234.8149\n",
            "61/147, train_loss: 5361.3594\n",
            "62/147, train_loss: 5365.9458\n",
            "63/147, train_loss: 5400.3057\n",
            "64/147, train_loss: 5336.8369\n",
            "65/147, train_loss: 5319.0083\n",
            "66/147, train_loss: 5247.6436\n",
            "67/147, train_loss: 5275.1616\n",
            "68/147, train_loss: 5374.5645\n",
            "69/147, train_loss: 5260.2261\n",
            "70/147, train_loss: 5220.9126\n",
            "71/147, train_loss: 5375.3809\n",
            "72/147, train_loss: 5244.8623\n",
            "73/147, train_loss: 5287.4756\n",
            "74/147, train_loss: 5419.9082\n",
            "75/147, train_loss: 5221.1558\n",
            "76/147, train_loss: 5311.9771\n",
            "77/147, train_loss: 5312.1533\n",
            "78/147, train_loss: 5307.1533\n",
            "79/147, train_loss: 5290.6548\n",
            "80/147, train_loss: 5212.1748\n",
            "81/147, train_loss: 5258.6299\n",
            "82/147, train_loss: 5308.8018\n",
            "83/147, train_loss: 5407.3267\n",
            "84/147, train_loss: 5263.7769\n",
            "85/147, train_loss: 5321.0430\n",
            "86/147, train_loss: 5346.2002\n",
            "87/147, train_loss: 5366.2012\n",
            "88/147, train_loss: 5283.9233\n",
            "89/147, train_loss: 5239.6973\n",
            "90/147, train_loss: 5270.7554\n",
            "91/147, train_loss: 5290.7021\n",
            "92/147, train_loss: 5374.0571\n",
            "93/147, train_loss: 5350.7656\n",
            "94/147, train_loss: 5346.4331\n",
            "95/147, train_loss: 5236.0469\n",
            "96/147, train_loss: 5390.4131\n",
            "97/147, train_loss: 5311.6382\n",
            "98/147, train_loss: 5244.7017\n",
            "99/147, train_loss: 5259.4014\n",
            "100/147, train_loss: 5334.2148\n",
            "101/147, train_loss: 5281.7852\n",
            "102/147, train_loss: 5372.7246\n",
            "103/147, train_loss: 5252.2803\n",
            "104/147, train_loss: 5273.7812\n",
            "105/147, train_loss: 5322.5518\n",
            "106/147, train_loss: 5351.9741\n",
            "107/147, train_loss: 5253.6411\n",
            "108/147, train_loss: 5307.1299\n",
            "109/147, train_loss: 5293.0059\n",
            "110/147, train_loss: 5381.5249\n",
            "111/147, train_loss: 5276.2959\n",
            "112/147, train_loss: 5246.3853\n",
            "113/147, train_loss: 5346.0586\n",
            "114/147, train_loss: 5383.5981\n",
            "115/147, train_loss: 5294.5381\n",
            "116/147, train_loss: 5288.0479\n",
            "117/147, train_loss: 5162.4199\n",
            "118/147, train_loss: 5246.1816\n",
            "119/147, train_loss: 5350.9883\n",
            "120/147, train_loss: 5320.9761\n",
            "121/147, train_loss: 5402.2627\n",
            "122/147, train_loss: 5291.4624\n",
            "123/147, train_loss: 5281.4248\n",
            "124/147, train_loss: 5292.9326\n",
            "125/147, train_loss: 5296.3359\n",
            "126/147, train_loss: 5231.8906\n",
            "127/147, train_loss: 5343.5781\n",
            "128/147, train_loss: 5469.7949\n",
            "129/147, train_loss: 5166.5342\n",
            "130/147, train_loss: 5345.3179\n",
            "131/147, train_loss: 5235.3984\n",
            "132/147, train_loss: 5280.7109\n",
            "133/147, train_loss: 5211.5034\n",
            "134/147, train_loss: 5262.4932\n",
            "135/147, train_loss: 5329.8535\n",
            "136/147, train_loss: 5248.6084\n",
            "137/147, train_loss: 5393.4209\n",
            "138/147, train_loss: 5330.2090\n",
            "139/147, train_loss: 5311.2002\n",
            "140/147, train_loss: 5329.7334\n",
            "141/147, train_loss: 5261.8247\n",
            "142/147, train_loss: 5204.2529\n",
            "143/147, train_loss: 5281.3838\n",
            "144/147, train_loss: 5293.6211\n",
            "145/147, train_loss: 5174.6919\n",
            "146/147, train_loss: 5278.3838\n",
            "147/147, train_loss: 5274.2192\n",
            "148/147, train_loss: 1158.5027\n",
            "epoch 21 average loss: 5273.0213\n",
            "Epoch 20: New best model saved with val_loss: 9519.614099451013\n",
            "Epoch 20: Average validation loss = 9519.614099451013\n",
            "----------\n",
            "epoch 22/60\n",
            "epoch 22 average loss: 5176.2099\n",
            "Epoch 21: Average validation loss = 9521.859130859375\n",
            "----------\n",
            "epoch 23/60\n",
            "epoch 23 average loss: 5086.5098\n",
            "Epoch 22: New best model saved with val_loss: 9473.927074535473\n",
            "Epoch 22: Average validation loss = 9473.927074535473\n",
            "----------\n",
            "epoch 24/60\n",
            "epoch 24 average loss: 4995.0441\n",
            "Epoch 23: New best model saved with val_loss: 9426.35278980152\n",
            "Epoch 23: Average validation loss = 9426.35278980152\n",
            "----------\n",
            "epoch 25/60\n",
            "epoch 25 average loss: 4915.6700\n",
            "Epoch 24: New best model saved with val_loss: 9353.012075063345\n",
            "Epoch 24: Average validation loss = 9353.012075063345\n",
            "----------\n",
            "epoch 26/60\n",
            "1/147, train_loss: 4869.4663\n",
            "2/147, train_loss: 4964.6572\n",
            "3/147, train_loss: 4887.3413\n",
            "4/147, train_loss: 4916.7798\n",
            "5/147, train_loss: 4811.2607\n",
            "6/147, train_loss: 4818.4292\n",
            "7/147, train_loss: 4905.9468\n",
            "8/147, train_loss: 4876.7925\n",
            "9/147, train_loss: 4842.9126\n",
            "10/147, train_loss: 4911.8774\n",
            "11/147, train_loss: 4958.4570\n",
            "12/147, train_loss: 4856.4932\n",
            "13/147, train_loss: 4862.2593\n",
            "14/147, train_loss: 4829.2041\n",
            "15/147, train_loss: 4841.6924\n",
            "16/147, train_loss: 4780.3833\n",
            "17/147, train_loss: 4811.3823\n",
            "18/147, train_loss: 4823.2656\n",
            "19/147, train_loss: 4732.3286\n",
            "20/147, train_loss: 4922.6338\n",
            "21/147, train_loss: 4849.4600\n",
            "22/147, train_loss: 4818.6670\n",
            "23/147, train_loss: 4927.8203\n",
            "24/147, train_loss: 4784.2617\n",
            "25/147, train_loss: 4884.8477\n",
            "26/147, train_loss: 4873.3384\n",
            "27/147, train_loss: 5029.4160\n",
            "28/147, train_loss: 4912.9263\n",
            "29/147, train_loss: 4923.5601\n",
            "30/147, train_loss: 4823.0498\n",
            "31/147, train_loss: 4912.3481\n",
            "32/147, train_loss: 4944.3662\n",
            "33/147, train_loss: 4865.2134\n",
            "34/147, train_loss: 4831.3042\n",
            "35/147, train_loss: 4957.9375\n",
            "36/147, train_loss: 4874.0835\n",
            "37/147, train_loss: 4844.3774\n",
            "38/147, train_loss: 4818.9976\n",
            "39/147, train_loss: 4878.4355\n",
            "40/147, train_loss: 4770.8457\n",
            "41/147, train_loss: 4942.4609\n",
            "42/147, train_loss: 4808.6670\n",
            "43/147, train_loss: 4853.9980\n",
            "44/147, train_loss: 4878.7129\n",
            "45/147, train_loss: 4906.3281\n",
            "46/147, train_loss: 4902.7612\n",
            "47/147, train_loss: 4809.6904\n",
            "48/147, train_loss: 4858.5649\n",
            "49/147, train_loss: 4819.9341\n",
            "50/147, train_loss: 4800.6099\n",
            "51/147, train_loss: 4817.2881\n",
            "52/147, train_loss: 4897.4868\n",
            "53/147, train_loss: 4854.8613\n",
            "54/147, train_loss: 4869.9053\n",
            "55/147, train_loss: 4893.7539\n",
            "56/147, train_loss: 4799.3325\n",
            "57/147, train_loss: 4855.0352\n",
            "58/147, train_loss: 4946.0957\n",
            "59/147, train_loss: 4843.7993\n",
            "60/147, train_loss: 4770.8618\n",
            "61/147, train_loss: 4800.3540\n",
            "62/147, train_loss: 4847.8252\n",
            "63/147, train_loss: 4887.7925\n",
            "64/147, train_loss: 4868.8799\n",
            "65/147, train_loss: 4834.9414\n",
            "66/147, train_loss: 4829.2871\n",
            "67/147, train_loss: 4832.9868\n",
            "68/147, train_loss: 4908.2070\n",
            "69/147, train_loss: 4900.9097\n",
            "70/147, train_loss: 4964.8711\n",
            "71/147, train_loss: 4874.2197\n",
            "72/147, train_loss: 4894.5645\n",
            "73/147, train_loss: 4858.5884\n",
            "74/147, train_loss: 4768.0254\n",
            "75/147, train_loss: 4889.9102\n",
            "76/147, train_loss: 4908.1851\n",
            "77/147, train_loss: 4811.5107\n",
            "78/147, train_loss: 4807.5576\n",
            "79/147, train_loss: 4834.9268\n",
            "80/147, train_loss: 4816.4785\n",
            "81/147, train_loss: 4811.9146\n",
            "82/147, train_loss: 4871.3789\n",
            "83/147, train_loss: 4830.9478\n",
            "84/147, train_loss: 4847.5249\n",
            "85/147, train_loss: 4823.8359\n",
            "86/147, train_loss: 4873.5190\n",
            "87/147, train_loss: 4911.6968\n",
            "88/147, train_loss: 4815.9243\n",
            "89/147, train_loss: 4839.8555\n",
            "90/147, train_loss: 4872.4912\n",
            "91/147, train_loss: 4793.7407\n",
            "92/147, train_loss: 4897.8110\n",
            "93/147, train_loss: 4733.5938\n",
            "94/147, train_loss: 4886.0811\n",
            "95/147, train_loss: 4971.0396\n",
            "96/147, train_loss: 4849.8877\n",
            "97/147, train_loss: 4835.7021\n",
            "98/147, train_loss: 4859.1006\n",
            "99/147, train_loss: 4875.1357\n",
            "100/147, train_loss: 4990.8525\n",
            "101/147, train_loss: 4857.7275\n",
            "102/147, train_loss: 4955.2769\n",
            "103/147, train_loss: 4854.3276\n",
            "104/147, train_loss: 4912.2749\n",
            "105/147, train_loss: 4859.5420\n",
            "106/147, train_loss: 4872.9414\n",
            "107/147, train_loss: 4837.4849\n",
            "108/147, train_loss: 4786.6680\n",
            "109/147, train_loss: 4912.1099\n",
            "110/147, train_loss: 4906.4785\n",
            "111/147, train_loss: 4836.7109\n",
            "112/147, train_loss: 4945.3311\n",
            "113/147, train_loss: 4864.6738\n",
            "114/147, train_loss: 4751.9404\n",
            "115/147, train_loss: 4850.1558\n",
            "116/147, train_loss: 4824.7583\n",
            "117/147, train_loss: 4850.6562\n",
            "118/147, train_loss: 4889.7422\n",
            "119/147, train_loss: 4788.5469\n",
            "120/147, train_loss: 4946.3408\n",
            "121/147, train_loss: 4875.9902\n",
            "122/147, train_loss: 4837.2905\n",
            "123/147, train_loss: 4767.8618\n",
            "124/147, train_loss: 5005.7446\n",
            "125/147, train_loss: 4856.6172\n",
            "126/147, train_loss: 4862.1001\n",
            "127/147, train_loss: 4895.9600\n",
            "128/147, train_loss: 4843.5020\n",
            "129/147, train_loss: 4929.8467\n",
            "130/147, train_loss: 4850.8174\n",
            "131/147, train_loss: 4851.7183\n",
            "132/147, train_loss: 4922.5913\n",
            "133/147, train_loss: 4833.4814\n",
            "134/147, train_loss: 4877.8252\n",
            "135/147, train_loss: 4826.2754\n",
            "136/147, train_loss: 4894.4756\n",
            "137/147, train_loss: 4840.7920\n",
            "138/147, train_loss: 4887.7344\n",
            "139/147, train_loss: 4877.8931\n",
            "140/147, train_loss: 4815.6714\n",
            "141/147, train_loss: 4767.5811\n",
            "142/147, train_loss: 4827.9141\n",
            "143/147, train_loss: 4947.9639\n",
            "144/147, train_loss: 4913.3164\n",
            "145/147, train_loss: 4930.8462\n",
            "146/147, train_loss: 4870.4053\n",
            "147/147, train_loss: 4981.0874\n",
            "148/147, train_loss: 1039.5010\n",
            "epoch 26 average loss: 4838.8346\n",
            "Epoch 25: Average validation loss = 9407.339256492822\n",
            "----------\n",
            "epoch 27/60\n",
            "epoch 27 average loss: 4776.9304\n",
            "Epoch 26: Average validation loss = 9461.305320945947\n",
            "----------\n",
            "epoch 28/60\n",
            "epoch 28 average loss: 4709.3670\n",
            "Epoch 27: New best model saved with val_loss: 9310.700564822635\n",
            "Epoch 27: Average validation loss = 9310.700564822635\n",
            "----------\n",
            "epoch 29/60\n",
            "epoch 29 average loss: 4643.3483\n",
            "Epoch 28: Average validation loss = 9375.285987647803\n",
            "----------\n",
            "epoch 30/60\n",
            "epoch 30 average loss: 4577.8510\n",
            "Epoch 29: Average validation loss = 9386.50671056799\n",
            "----------\n",
            "epoch 31/60\n",
            "1/147, train_loss: 4534.6152\n",
            "2/147, train_loss: 4513.7705\n",
            "3/147, train_loss: 4555.9604\n",
            "4/147, train_loss: 4530.7764\n",
            "5/147, train_loss: 4505.9795\n",
            "6/147, train_loss: 4470.7993\n",
            "7/147, train_loss: 4506.8696\n",
            "8/147, train_loss: 4621.1206\n",
            "9/147, train_loss: 4505.6377\n",
            "10/147, train_loss: 4355.1611\n",
            "11/147, train_loss: 4582.4658\n",
            "12/147, train_loss: 4467.9668\n",
            "13/147, train_loss: 4561.5713\n",
            "14/147, train_loss: 4485.1167\n",
            "15/147, train_loss: 4624.5908\n",
            "16/147, train_loss: 4563.8965\n",
            "17/147, train_loss: 4528.0376\n",
            "18/147, train_loss: 4537.1167\n",
            "19/147, train_loss: 4654.9546\n",
            "20/147, train_loss: 4552.0332\n",
            "21/147, train_loss: 4554.5977\n",
            "22/147, train_loss: 4542.4102\n",
            "23/147, train_loss: 4516.4336\n",
            "24/147, train_loss: 4460.2139\n",
            "25/147, train_loss: 4577.9448\n",
            "26/147, train_loss: 4394.3022\n",
            "27/147, train_loss: 4603.8311\n",
            "28/147, train_loss: 4491.1069\n",
            "29/147, train_loss: 4675.9058\n",
            "30/147, train_loss: 4526.0063\n",
            "31/147, train_loss: 4546.7339\n",
            "32/147, train_loss: 4593.0957\n",
            "33/147, train_loss: 4587.1426\n",
            "34/147, train_loss: 4572.5005\n",
            "35/147, train_loss: 4569.1680\n",
            "36/147, train_loss: 4576.5771\n",
            "37/147, train_loss: 4547.8989\n",
            "38/147, train_loss: 4418.2051\n",
            "39/147, train_loss: 4501.5151\n",
            "40/147, train_loss: 4525.8955\n",
            "41/147, train_loss: 4474.7866\n",
            "42/147, train_loss: 4570.6851\n",
            "43/147, train_loss: 4512.1240\n",
            "44/147, train_loss: 4494.9150\n",
            "45/147, train_loss: 4498.2490\n",
            "46/147, train_loss: 4493.2192\n",
            "47/147, train_loss: 4694.2114\n",
            "48/147, train_loss: 4562.8008\n",
            "49/147, train_loss: 4523.8452\n",
            "50/147, train_loss: 4628.6885\n",
            "51/147, train_loss: 4501.7847\n",
            "52/147, train_loss: 4464.0830\n",
            "53/147, train_loss: 4631.2441\n",
            "54/147, train_loss: 4625.8906\n",
            "55/147, train_loss: 4572.9697\n",
            "56/147, train_loss: 4536.8306\n",
            "57/147, train_loss: 4593.4375\n",
            "58/147, train_loss: 4518.9541\n",
            "59/147, train_loss: 4430.4331\n",
            "60/147, train_loss: 4595.7783\n",
            "61/147, train_loss: 4467.1660\n",
            "62/147, train_loss: 4600.6514\n",
            "63/147, train_loss: 4493.5732\n",
            "64/147, train_loss: 4596.8350\n",
            "65/147, train_loss: 4553.7690\n",
            "66/147, train_loss: 4650.7495\n",
            "67/147, train_loss: 4586.7314\n",
            "68/147, train_loss: 4585.3535\n",
            "69/147, train_loss: 4478.1904\n",
            "70/147, train_loss: 4439.5078\n",
            "71/147, train_loss: 4601.3716\n",
            "72/147, train_loss: 4501.4165\n",
            "73/147, train_loss: 4520.5186\n",
            "74/147, train_loss: 4502.4712\n",
            "75/147, train_loss: 4593.6299\n",
            "76/147, train_loss: 4592.7085\n",
            "77/147, train_loss: 4476.9692\n",
            "78/147, train_loss: 4590.3936\n",
            "79/147, train_loss: 4508.1997\n",
            "80/147, train_loss: 4500.3228\n",
            "81/147, train_loss: 4461.8999\n",
            "82/147, train_loss: 4506.1558\n",
            "83/147, train_loss: 4535.4800\n",
            "84/147, train_loss: 4584.1255\n",
            "85/147, train_loss: 4551.7412\n",
            "86/147, train_loss: 4534.2930\n",
            "87/147, train_loss: 4596.5195\n",
            "88/147, train_loss: 4580.0059\n",
            "89/147, train_loss: 4539.3633\n",
            "90/147, train_loss: 4611.3311\n",
            "91/147, train_loss: 4495.2739\n",
            "92/147, train_loss: 4457.8735\n",
            "93/147, train_loss: 4564.5322\n",
            "94/147, train_loss: 4529.4268\n",
            "95/147, train_loss: 4531.8730\n",
            "96/147, train_loss: 4486.7642\n",
            "97/147, train_loss: 4501.2109\n",
            "98/147, train_loss: 4566.6729\n",
            "99/147, train_loss: 4508.6714\n",
            "100/147, train_loss: 4544.6348\n",
            "101/147, train_loss: 4634.3447\n",
            "102/147, train_loss: 4629.0552\n",
            "103/147, train_loss: 4488.6685\n",
            "104/147, train_loss: 4439.1816\n",
            "105/147, train_loss: 4589.8076\n",
            "106/147, train_loss: 4630.7500\n",
            "107/147, train_loss: 4623.1792\n",
            "108/147, train_loss: 4635.0356\n",
            "109/147, train_loss: 4604.0225\n",
            "110/147, train_loss: 4615.1377\n",
            "111/147, train_loss: 4543.2568\n",
            "112/147, train_loss: 4566.3506\n",
            "113/147, train_loss: 4517.1006\n",
            "114/147, train_loss: 4611.2837\n",
            "115/147, train_loss: 4501.8418\n",
            "116/147, train_loss: 4465.5220\n",
            "117/147, train_loss: 4553.2393\n",
            "118/147, train_loss: 4615.0723\n",
            "119/147, train_loss: 4525.8169\n",
            "120/147, train_loss: 4557.6191\n",
            "121/147, train_loss: 4575.9556\n",
            "122/147, train_loss: 4672.5864\n",
            "123/147, train_loss: 4600.2285\n",
            "124/147, train_loss: 4648.3477\n",
            "125/147, train_loss: 4557.7754\n",
            "126/147, train_loss: 4520.1465\n",
            "127/147, train_loss: 4445.7065\n",
            "128/147, train_loss: 4468.0562\n",
            "129/147, train_loss: 4696.5967\n",
            "130/147, train_loss: 4595.4014\n",
            "131/147, train_loss: 4542.1475\n",
            "132/147, train_loss: 4617.1143\n",
            "133/147, train_loss: 4584.4858\n",
            "134/147, train_loss: 4649.6699\n",
            "135/147, train_loss: 4650.5986\n",
            "136/147, train_loss: 4511.6035\n",
            "137/147, train_loss: 4521.1567\n",
            "138/147, train_loss: 4519.1758\n",
            "139/147, train_loss: 4578.8076\n",
            "140/147, train_loss: 4690.1064\n",
            "141/147, train_loss: 4597.9863\n",
            "142/147, train_loss: 4614.0601\n",
            "143/147, train_loss: 4660.1509\n",
            "144/147, train_loss: 4608.6025\n",
            "145/147, train_loss: 4525.6011\n",
            "146/147, train_loss: 4542.7383\n",
            "147/147, train_loss: 4556.6992\n",
            "148/147, train_loss: 986.6443\n",
            "epoch 31 average loss: 4526.8761\n",
            "Epoch 30: New best model saved with val_loss: 9285.4912109375\n",
            "Epoch 30: Average validation loss = 9285.4912109375\n",
            "----------\n",
            "epoch 32/60\n",
            "epoch 32 average loss: 4471.4656\n",
            "Epoch 31: Average validation loss = 9330.800345755912\n",
            "----------\n",
            "epoch 33/60\n",
            "epoch 33 average loss: 4421.6303\n",
            "Epoch 32: New best model saved with val_loss: 9281.268943992822\n",
            "Epoch 32: Average validation loss = 9281.268943992822\n",
            "----------\n",
            "epoch 34/60\n",
            "epoch 34 average loss: 4369.6518\n",
            "Epoch 33: Average validation loss = 9296.421102987753\n",
            "----------\n",
            "epoch 35/60\n",
            "epoch 35 average loss: 4323.7727\n",
            "Epoch 34: New best model saved with val_loss: 9240.917863175675\n",
            "Epoch 34: Average validation loss = 9240.917863175675\n",
            "----------\n",
            "epoch 36/60\n",
            "1/147, train_loss: 4226.9082\n",
            "2/147, train_loss: 4266.0195\n",
            "3/147, train_loss: 4297.5317\n",
            "4/147, train_loss: 4289.8076\n",
            "5/147, train_loss: 4346.4658\n",
            "6/147, train_loss: 4288.3672\n",
            "7/147, train_loss: 4360.4917\n",
            "8/147, train_loss: 4400.4775\n",
            "9/147, train_loss: 4278.6528\n",
            "10/147, train_loss: 4234.4219\n",
            "11/147, train_loss: 4259.3853\n",
            "12/147, train_loss: 4303.1899\n",
            "13/147, train_loss: 4348.6235\n",
            "14/147, train_loss: 4280.4731\n",
            "15/147, train_loss: 4232.9419\n",
            "16/147, train_loss: 4289.6392\n",
            "17/147, train_loss: 4271.6240\n",
            "18/147, train_loss: 4352.1992\n",
            "19/147, train_loss: 4275.2900\n",
            "20/147, train_loss: 4281.6426\n",
            "21/147, train_loss: 4166.7734\n",
            "22/147, train_loss: 4357.6885\n",
            "23/147, train_loss: 4380.4189\n",
            "24/147, train_loss: 4380.4844\n",
            "25/147, train_loss: 4250.2573\n",
            "26/147, train_loss: 4269.9834\n",
            "27/147, train_loss: 4338.1982\n",
            "28/147, train_loss: 4306.0566\n",
            "29/147, train_loss: 4313.5010\n",
            "30/147, train_loss: 4344.7783\n",
            "31/147, train_loss: 4253.1152\n",
            "32/147, train_loss: 4267.6904\n",
            "33/147, train_loss: 4296.7900\n",
            "34/147, train_loss: 4170.5259\n",
            "35/147, train_loss: 4259.3726\n",
            "36/147, train_loss: 4120.4277\n",
            "37/147, train_loss: 4284.5034\n",
            "38/147, train_loss: 4243.5190\n",
            "39/147, train_loss: 4205.9556\n",
            "40/147, train_loss: 4225.2993\n",
            "41/147, train_loss: 4314.1162\n",
            "42/147, train_loss: 4319.5244\n",
            "43/147, train_loss: 4230.4658\n",
            "44/147, train_loss: 4327.5913\n",
            "45/147, train_loss: 4338.4956\n",
            "46/147, train_loss: 4228.5527\n",
            "47/147, train_loss: 4204.1465\n",
            "48/147, train_loss: 4338.6533\n",
            "49/147, train_loss: 4282.9111\n",
            "50/147, train_loss: 4413.8408\n",
            "51/147, train_loss: 4339.5146\n",
            "52/147, train_loss: 4482.8281\n",
            "53/147, train_loss: 4274.7485\n",
            "54/147, train_loss: 4284.6948\n",
            "55/147, train_loss: 4327.4409\n",
            "56/147, train_loss: 4378.6963\n",
            "57/147, train_loss: 4246.9531\n",
            "58/147, train_loss: 4260.3965\n",
            "59/147, train_loss: 4330.5508\n",
            "60/147, train_loss: 4256.0083\n",
            "61/147, train_loss: 4313.6250\n",
            "62/147, train_loss: 4331.0322\n",
            "63/147, train_loss: 4228.9883\n",
            "64/147, train_loss: 4240.9492\n",
            "65/147, train_loss: 4287.5620\n",
            "66/147, train_loss: 4161.4893\n",
            "67/147, train_loss: 4272.5093\n",
            "68/147, train_loss: 4234.2598\n",
            "69/147, train_loss: 4216.2930\n",
            "70/147, train_loss: 4383.8101\n",
            "71/147, train_loss: 4236.7969\n",
            "72/147, train_loss: 4418.7964\n",
            "73/147, train_loss: 4278.8232\n",
            "74/147, train_loss: 4264.0728\n",
            "75/147, train_loss: 4299.3950\n",
            "76/147, train_loss: 4290.4878\n",
            "77/147, train_loss: 4438.6982\n",
            "78/147, train_loss: 4444.4756\n",
            "79/147, train_loss: 4237.9834\n",
            "80/147, train_loss: 4442.8638\n",
            "81/147, train_loss: 4259.0991\n",
            "82/147, train_loss: 4307.6025\n",
            "83/147, train_loss: 4211.7256\n",
            "84/147, train_loss: 4357.4219\n",
            "85/147, train_loss: 4334.5044\n",
            "86/147, train_loss: 4283.1899\n",
            "87/147, train_loss: 4298.3613\n",
            "88/147, train_loss: 4243.7832\n",
            "89/147, train_loss: 4332.4844\n",
            "90/147, train_loss: 4295.8560\n",
            "91/147, train_loss: 4329.2695\n",
            "92/147, train_loss: 4446.4580\n",
            "93/147, train_loss: 4299.0093\n",
            "94/147, train_loss: 4263.5376\n",
            "95/147, train_loss: 4288.8477\n",
            "96/147, train_loss: 4268.0649\n",
            "97/147, train_loss: 4331.6343\n",
            "98/147, train_loss: 4291.9702\n",
            "99/147, train_loss: 4300.4106\n",
            "100/147, train_loss: 4329.0605\n",
            "101/147, train_loss: 4295.9624\n",
            "102/147, train_loss: 4340.8252\n",
            "103/147, train_loss: 4350.9067\n",
            "104/147, train_loss: 4326.8413\n",
            "105/147, train_loss: 4230.6133\n",
            "106/147, train_loss: 4247.1870\n",
            "107/147, train_loss: 4265.6094\n",
            "108/147, train_loss: 4385.8926\n",
            "109/147, train_loss: 4302.9399\n",
            "110/147, train_loss: 4223.7539\n",
            "111/147, train_loss: 4326.8682\n",
            "112/147, train_loss: 4456.5688\n",
            "113/147, train_loss: 4299.8315\n",
            "114/147, train_loss: 4320.0469\n",
            "115/147, train_loss: 4276.0034\n",
            "116/147, train_loss: 4269.6343\n",
            "117/147, train_loss: 4312.1772\n",
            "118/147, train_loss: 4342.8657\n",
            "119/147, train_loss: 4332.2432\n",
            "120/147, train_loss: 4205.3315\n",
            "121/147, train_loss: 4418.3027\n",
            "122/147, train_loss: 4238.9087\n",
            "123/147, train_loss: 4382.6079\n",
            "124/147, train_loss: 4355.0352\n",
            "125/147, train_loss: 4364.5674\n",
            "126/147, train_loss: 4282.0151\n",
            "127/147, train_loss: 4350.2461\n",
            "128/147, train_loss: 4262.7729\n",
            "129/147, train_loss: 4175.4155\n",
            "130/147, train_loss: 4410.3252\n",
            "131/147, train_loss: 4405.2412\n",
            "132/147, train_loss: 4392.6904\n",
            "133/147, train_loss: 4299.7002\n",
            "134/147, train_loss: 4321.1431\n",
            "135/147, train_loss: 4474.0430\n",
            "136/147, train_loss: 4265.1768\n",
            "137/147, train_loss: 4314.8232\n",
            "138/147, train_loss: 4317.5195\n",
            "139/147, train_loss: 4337.7974\n",
            "140/147, train_loss: 4441.5688\n",
            "141/147, train_loss: 4320.7979\n",
            "142/147, train_loss: 4255.5674\n",
            "143/147, train_loss: 4278.1802\n",
            "144/147, train_loss: 4219.1152\n",
            "145/147, train_loss: 4530.8926\n",
            "146/147, train_loss: 4357.4170\n",
            "147/147, train_loss: 4442.7266\n",
            "148/147, train_loss: 927.6016\n",
            "epoch 36 average loss: 4282.7644\n",
            "Epoch 35: Average validation loss = 9353.95237278294\n",
            "----------\n",
            "epoch 37/60\n",
            "epoch 37 average loss: 4246.1273\n",
            "Epoch 36: Average validation loss = 9306.418536211993\n",
            "----------\n",
            "epoch 38/60\n",
            "epoch 38 average loss: 4203.7317\n",
            "Epoch 37: Average validation loss = 9385.721785261825\n",
            "----------\n",
            "epoch 39/60\n",
            "epoch 39 average loss: 4160.7162\n",
            "Epoch 38: Average validation loss = 9402.750428895693\n",
            "----------\n",
            "epoch 40/60\n",
            "epoch 40 average loss: 4122.4591\n",
            "Epoch 39: Average validation loss = 9342.488400021115\n",
            "----------\n",
            "epoch 41/60\n",
            "1/147, train_loss: 4089.7864\n",
            "2/147, train_loss: 4176.5176\n",
            "3/147, train_loss: 4089.1982\n",
            "4/147, train_loss: 4113.3477\n",
            "5/147, train_loss: 4133.4087\n",
            "6/147, train_loss: 4252.8154\n",
            "7/147, train_loss: 4168.2383\n",
            "8/147, train_loss: 4046.3203\n",
            "9/147, train_loss: 4180.4038\n",
            "10/147, train_loss: 4034.5754\n",
            "11/147, train_loss: 4049.0542\n",
            "12/147, train_loss: 4103.9385\n",
            "13/147, train_loss: 4087.9763\n",
            "14/147, train_loss: 4138.4990\n",
            "15/147, train_loss: 3990.1919\n",
            "16/147, train_loss: 4089.6863\n",
            "17/147, train_loss: 4088.0854\n",
            "18/147, train_loss: 4078.0283\n",
            "19/147, train_loss: 4059.2693\n",
            "20/147, train_loss: 4173.2661\n",
            "21/147, train_loss: 4198.8516\n",
            "22/147, train_loss: 4071.2988\n",
            "23/147, train_loss: 4093.8831\n",
            "24/147, train_loss: 4142.4204\n",
            "25/147, train_loss: 4177.1675\n",
            "26/147, train_loss: 4169.0400\n",
            "27/147, train_loss: 4045.5017\n",
            "28/147, train_loss: 4121.9609\n",
            "29/147, train_loss: 4100.5942\n",
            "30/147, train_loss: 4037.9080\n",
            "31/147, train_loss: 4164.2598\n",
            "32/147, train_loss: 4121.6318\n",
            "33/147, train_loss: 4141.3198\n",
            "34/147, train_loss: 4220.4448\n",
            "35/147, train_loss: 4134.1953\n",
            "36/147, train_loss: 4207.3032\n",
            "37/147, train_loss: 4077.4968\n",
            "38/147, train_loss: 3872.7754\n",
            "39/147, train_loss: 4213.7168\n",
            "40/147, train_loss: 4068.8406\n",
            "41/147, train_loss: 4065.4949\n",
            "42/147, train_loss: 4131.0977\n",
            "43/147, train_loss: 4051.7786\n",
            "44/147, train_loss: 4120.3750\n",
            "45/147, train_loss: 4182.8125\n",
            "46/147, train_loss: 4173.9585\n",
            "47/147, train_loss: 4153.9214\n",
            "48/147, train_loss: 4094.3398\n",
            "49/147, train_loss: 4040.9719\n",
            "50/147, train_loss: 4146.0718\n",
            "51/147, train_loss: 4166.3911\n",
            "52/147, train_loss: 4081.1196\n",
            "53/147, train_loss: 4127.2095\n",
            "54/147, train_loss: 4138.2114\n",
            "55/147, train_loss: 4166.7266\n",
            "56/147, train_loss: 4209.6631\n",
            "57/147, train_loss: 4095.3796\n",
            "58/147, train_loss: 3998.5894\n",
            "59/147, train_loss: 4045.0923\n",
            "60/147, train_loss: 4029.0818\n",
            "61/147, train_loss: 4095.0215\n",
            "62/147, train_loss: 4150.1108\n",
            "63/147, train_loss: 4115.6113\n",
            "64/147, train_loss: 4158.4321\n",
            "65/147, train_loss: 4175.3989\n",
            "66/147, train_loss: 4189.0962\n",
            "67/147, train_loss: 4128.7690\n",
            "68/147, train_loss: 4123.4814\n",
            "69/147, train_loss: 4137.5562\n",
            "70/147, train_loss: 4051.6458\n",
            "71/147, train_loss: 4129.2588\n",
            "72/147, train_loss: 4130.3237\n",
            "73/147, train_loss: 4141.0483\n",
            "74/147, train_loss: 4106.7578\n",
            "75/147, train_loss: 4147.1006\n",
            "76/147, train_loss: 4077.5955\n",
            "77/147, train_loss: 4174.0664\n",
            "78/147, train_loss: 4145.8486\n",
            "79/147, train_loss: 4114.0117\n",
            "80/147, train_loss: 4135.3784\n",
            "81/147, train_loss: 4164.6948\n",
            "82/147, train_loss: 4080.7678\n",
            "83/147, train_loss: 4117.2266\n",
            "84/147, train_loss: 4066.9604\n",
            "85/147, train_loss: 4188.3965\n",
            "86/147, train_loss: 4164.0942\n",
            "87/147, train_loss: 4097.4917\n",
            "88/147, train_loss: 4108.5303\n",
            "89/147, train_loss: 3997.7769\n",
            "90/147, train_loss: 4094.9258\n",
            "91/147, train_loss: 4067.1670\n",
            "92/147, train_loss: 4120.3403\n",
            "93/147, train_loss: 4098.8389\n",
            "94/147, train_loss: 4157.1182\n",
            "95/147, train_loss: 4114.8491\n",
            "96/147, train_loss: 4125.5811\n",
            "97/147, train_loss: 4059.7725\n",
            "98/147, train_loss: 4120.2720\n",
            "99/147, train_loss: 3992.4751\n",
            "100/147, train_loss: 4063.9553\n",
            "101/147, train_loss: 4094.7380\n",
            "102/147, train_loss: 4168.9028\n",
            "103/147, train_loss: 4087.9563\n",
            "104/147, train_loss: 4059.4529\n",
            "105/147, train_loss: 4110.1890\n",
            "106/147, train_loss: 4089.9233\n",
            "107/147, train_loss: 4028.3384\n",
            "108/147, train_loss: 4064.4736\n",
            "109/147, train_loss: 4028.8838\n",
            "110/147, train_loss: 4002.5454\n",
            "111/147, train_loss: 4105.9287\n",
            "112/147, train_loss: 4131.3335\n",
            "113/147, train_loss: 4064.4800\n",
            "114/147, train_loss: 4090.9399\n",
            "115/147, train_loss: 4110.3403\n",
            "116/147, train_loss: 4148.7676\n",
            "117/147, train_loss: 4153.5112\n",
            "118/147, train_loss: 4064.5342\n",
            "119/147, train_loss: 4092.9187\n",
            "120/147, train_loss: 4089.7944\n",
            "121/147, train_loss: 4191.7969\n",
            "122/147, train_loss: 4138.4219\n",
            "123/147, train_loss: 4071.1348\n",
            "124/147, train_loss: 4175.2129\n",
            "125/147, train_loss: 4066.7710\n",
            "126/147, train_loss: 4148.1367\n",
            "127/147, train_loss: 4111.0166\n",
            "128/147, train_loss: 4021.9316\n",
            "129/147, train_loss: 4202.0781\n",
            "130/147, train_loss: 4025.7070\n",
            "131/147, train_loss: 4090.8164\n",
            "132/147, train_loss: 4242.1460\n",
            "133/147, train_loss: 3996.8235\n",
            "134/147, train_loss: 4054.7087\n",
            "135/147, train_loss: 4038.2698\n",
            "136/147, train_loss: 4103.1509\n",
            "137/147, train_loss: 4171.7979\n",
            "138/147, train_loss: 4226.3682\n",
            "139/147, train_loss: 4112.0322\n",
            "140/147, train_loss: 4129.7266\n",
            "141/147, train_loss: 4083.2336\n",
            "142/147, train_loss: 4121.2915\n",
            "143/147, train_loss: 4069.1931\n",
            "144/147, train_loss: 4109.1406\n",
            "145/147, train_loss: 4150.3857\n",
            "146/147, train_loss: 4094.1421\n",
            "147/147, train_loss: 4108.1084\n",
            "148/147, train_loss: 895.2151\n",
            "epoch 41 average loss: 4088.5538\n",
            "Epoch 40: Average validation loss = 9320.055479307432\n",
            "----------\n",
            "epoch 42/60\n",
            "epoch 42 average loss: 4047.6795\n",
            "Epoch 41: Average validation loss = 9391.906744879645\n",
            "----------\n",
            "epoch 43/60\n",
            "epoch 43 average loss: 4013.5959\n",
            "Epoch 42: Average validation loss = 9394.311094541807\n",
            "----------\n",
            "epoch 44/60\n",
            "epoch 44 average loss: 3983.3162\n",
            "Epoch 43: Average validation loss = 9326.872994087838\n",
            "----------\n",
            "epoch 45/60\n",
            "epoch 45 average loss: 3954.2588\n",
            "Epoch 44: Average validation loss = 9457.73402528505\n",
            "----------\n",
            "epoch 46/60\n",
            "1/147, train_loss: 4033.9429\n",
            "2/147, train_loss: 3982.3191\n",
            "3/147, train_loss: 3928.7922\n",
            "4/147, train_loss: 4004.8586\n",
            "5/147, train_loss: 3922.7505\n",
            "6/147, train_loss: 3990.8760\n",
            "7/147, train_loss: 3983.1086\n",
            "8/147, train_loss: 3917.8716\n",
            "9/147, train_loss: 3925.0510\n",
            "10/147, train_loss: 3946.5908\n",
            "11/147, train_loss: 4001.9590\n",
            "12/147, train_loss: 3861.1982\n",
            "13/147, train_loss: 3886.4651\n",
            "14/147, train_loss: 3877.3979\n",
            "15/147, train_loss: 3949.5129\n",
            "16/147, train_loss: 3916.0239\n",
            "17/147, train_loss: 3916.1934\n",
            "18/147, train_loss: 3871.8293\n",
            "19/147, train_loss: 4035.0835\n",
            "20/147, train_loss: 3838.4253\n",
            "21/147, train_loss: 3888.4119\n",
            "22/147, train_loss: 3824.4048\n",
            "23/147, train_loss: 3887.4221\n",
            "24/147, train_loss: 4013.7905\n",
            "25/147, train_loss: 3950.6558\n",
            "26/147, train_loss: 3904.6689\n",
            "27/147, train_loss: 4022.9146\n",
            "28/147, train_loss: 3985.6421\n",
            "29/147, train_loss: 3846.8232\n",
            "30/147, train_loss: 4005.9182\n",
            "31/147, train_loss: 3928.0146\n",
            "32/147, train_loss: 3914.6421\n",
            "33/147, train_loss: 3929.6052\n",
            "34/147, train_loss: 3894.2808\n",
            "35/147, train_loss: 3987.6233\n",
            "36/147, train_loss: 3965.7456\n",
            "37/147, train_loss: 3898.3210\n",
            "38/147, train_loss: 3953.4426\n",
            "39/147, train_loss: 3996.9263\n",
            "40/147, train_loss: 3972.3096\n",
            "41/147, train_loss: 3920.3984\n",
            "42/147, train_loss: 3934.2866\n",
            "43/147, train_loss: 3828.4946\n",
            "44/147, train_loss: 3858.5469\n",
            "45/147, train_loss: 3903.6963\n",
            "46/147, train_loss: 3947.1665\n",
            "47/147, train_loss: 3926.4407\n",
            "48/147, train_loss: 3979.8726\n",
            "49/147, train_loss: 3984.8247\n",
            "50/147, train_loss: 3900.3232\n",
            "51/147, train_loss: 3916.7861\n",
            "52/147, train_loss: 3872.9761\n",
            "53/147, train_loss: 3843.2178\n",
            "54/147, train_loss: 4009.8623\n",
            "55/147, train_loss: 4035.5068\n",
            "56/147, train_loss: 3940.4534\n",
            "57/147, train_loss: 3952.3333\n",
            "58/147, train_loss: 3927.6226\n",
            "59/147, train_loss: 3934.5439\n",
            "60/147, train_loss: 4050.5662\n",
            "61/147, train_loss: 4061.5310\n",
            "62/147, train_loss: 4009.4680\n",
            "63/147, train_loss: 4012.7295\n",
            "64/147, train_loss: 3877.2600\n",
            "65/147, train_loss: 3994.0454\n",
            "66/147, train_loss: 3876.7310\n",
            "67/147, train_loss: 3805.6848\n",
            "68/147, train_loss: 3959.0647\n",
            "69/147, train_loss: 3971.2593\n",
            "70/147, train_loss: 3910.7126\n",
            "71/147, train_loss: 3994.5146\n",
            "72/147, train_loss: 3974.8379\n",
            "73/147, train_loss: 4011.6885\n",
            "74/147, train_loss: 3912.8894\n",
            "75/147, train_loss: 3998.1362\n",
            "76/147, train_loss: 3953.0554\n",
            "77/147, train_loss: 3935.5046\n",
            "78/147, train_loss: 3990.3496\n",
            "79/147, train_loss: 3985.6230\n",
            "80/147, train_loss: 3915.1960\n",
            "81/147, train_loss: 3966.2354\n",
            "82/147, train_loss: 3986.3560\n",
            "83/147, train_loss: 3902.5576\n",
            "84/147, train_loss: 3863.4685\n",
            "85/147, train_loss: 3933.4214\n",
            "86/147, train_loss: 3939.9497\n",
            "87/147, train_loss: 3922.4771\n",
            "88/147, train_loss: 3972.9050\n",
            "89/147, train_loss: 3900.8599\n",
            "90/147, train_loss: 3878.2715\n",
            "91/147, train_loss: 3893.2646\n",
            "92/147, train_loss: 4101.7871\n",
            "93/147, train_loss: 3973.8191\n",
            "94/147, train_loss: 3892.6917\n",
            "95/147, train_loss: 3958.0190\n",
            "96/147, train_loss: 3952.0344\n",
            "97/147, train_loss: 3989.5664\n",
            "98/147, train_loss: 3896.1946\n",
            "99/147, train_loss: 3874.6951\n",
            "100/147, train_loss: 4062.4543\n",
            "101/147, train_loss: 4083.6494\n",
            "102/147, train_loss: 4012.4861\n",
            "103/147, train_loss: 3934.3452\n",
            "104/147, train_loss: 4040.6226\n",
            "105/147, train_loss: 3840.3062\n",
            "106/147, train_loss: 3912.1636\n",
            "107/147, train_loss: 4101.5479\n",
            "108/147, train_loss: 3859.0691\n",
            "109/147, train_loss: 3859.4316\n",
            "110/147, train_loss: 3938.8745\n",
            "111/147, train_loss: 3945.3113\n",
            "112/147, train_loss: 3891.0259\n",
            "113/147, train_loss: 3980.1921\n",
            "114/147, train_loss: 4016.8381\n",
            "115/147, train_loss: 4058.5928\n",
            "116/147, train_loss: 3950.6411\n",
            "117/147, train_loss: 4005.1084\n",
            "118/147, train_loss: 3928.0076\n",
            "119/147, train_loss: 3918.5098\n",
            "120/147, train_loss: 3910.1331\n",
            "121/147, train_loss: 3952.7859\n",
            "122/147, train_loss: 3805.3997\n",
            "123/147, train_loss: 3927.4656\n",
            "124/147, train_loss: 3928.5063\n",
            "125/147, train_loss: 3941.3408\n",
            "126/147, train_loss: 3886.5210\n",
            "127/147, train_loss: 3955.8105\n",
            "128/147, train_loss: 3886.0249\n",
            "129/147, train_loss: 3953.3398\n",
            "130/147, train_loss: 3964.8071\n",
            "131/147, train_loss: 3846.9124\n",
            "132/147, train_loss: 3966.2676\n",
            "133/147, train_loss: 3925.4778\n",
            "134/147, train_loss: 3977.0581\n",
            "135/147, train_loss: 3880.6570\n",
            "136/147, train_loss: 3981.8608\n",
            "137/147, train_loss: 3942.4758\n",
            "138/147, train_loss: 3939.1021\n",
            "139/147, train_loss: 3916.8423\n",
            "140/147, train_loss: 3942.6851\n",
            "141/147, train_loss: 3834.0962\n",
            "142/147, train_loss: 3938.7334\n",
            "143/147, train_loss: 3909.9890\n",
            "144/147, train_loss: 4037.5234\n",
            "145/147, train_loss: 3923.9451\n",
            "146/147, train_loss: 3907.7395\n",
            "147/147, train_loss: 3938.6636\n",
            "148/147, train_loss: 825.1468\n",
            "epoch 46 average loss: 3920.7100\n",
            "Epoch 45: Average validation loss = 9393.102948163007\n",
            "----------\n",
            "epoch 47/60\n",
            "epoch 47 average loss: 3892.6122\n",
            "Epoch 46: Average validation loss = 9392.7364666913\n",
            "----------\n",
            "epoch 48/60\n",
            "epoch 48 average loss: 3868.4308\n",
            "Epoch 47: Average validation loss = 9403.370908994932\n",
            "----------\n",
            "epoch 49/60\n",
            "epoch 49 average loss: 3835.7283\n",
            "Epoch 48: Average validation loss = 9311.919578758447\n",
            "----------\n",
            "epoch 50/60\n",
            "epoch 50 average loss: 3813.1450\n",
            "Epoch 49: Average validation loss = 9437.118124472128\n",
            "----------\n",
            "epoch 51/60\n",
            "1/147, train_loss: 3755.0820\n",
            "2/147, train_loss: 3773.3416\n",
            "3/147, train_loss: 3844.4250\n",
            "4/147, train_loss: 3739.6196\n",
            "5/147, train_loss: 3835.7034\n",
            "6/147, train_loss: 3810.1602\n",
            "7/147, train_loss: 3830.1145\n",
            "8/147, train_loss: 3770.7561\n",
            "9/147, train_loss: 3745.8452\n",
            "10/147, train_loss: 3901.3877\n",
            "11/147, train_loss: 3716.5430\n",
            "12/147, train_loss: 3846.9150\n",
            "13/147, train_loss: 3890.6543\n",
            "14/147, train_loss: 3739.7959\n",
            "15/147, train_loss: 3824.5320\n",
            "16/147, train_loss: 3870.8159\n",
            "17/147, train_loss: 3738.0295\n",
            "18/147, train_loss: 3778.2737\n",
            "19/147, train_loss: 3744.0020\n",
            "20/147, train_loss: 3836.7236\n",
            "21/147, train_loss: 3799.8677\n",
            "22/147, train_loss: 3855.4387\n",
            "23/147, train_loss: 3847.7461\n",
            "24/147, train_loss: 3778.7380\n",
            "25/147, train_loss: 3722.5430\n",
            "26/147, train_loss: 3706.7959\n",
            "27/147, train_loss: 3856.9250\n",
            "28/147, train_loss: 3802.7056\n",
            "29/147, train_loss: 3870.8674\n",
            "30/147, train_loss: 3784.0054\n",
            "31/147, train_loss: 3718.5259\n",
            "32/147, train_loss: 3818.8474\n",
            "33/147, train_loss: 3724.0791\n",
            "34/147, train_loss: 3790.8330\n",
            "35/147, train_loss: 3833.0068\n",
            "36/147, train_loss: 3759.2170\n",
            "37/147, train_loss: 3775.5371\n",
            "38/147, train_loss: 3782.8940\n",
            "39/147, train_loss: 3754.5413\n",
            "40/147, train_loss: 3893.9990\n",
            "41/147, train_loss: 3854.7688\n",
            "42/147, train_loss: 3812.9629\n",
            "43/147, train_loss: 3763.8052\n",
            "44/147, train_loss: 3815.1147\n",
            "45/147, train_loss: 3823.6646\n",
            "46/147, train_loss: 3768.2610\n",
            "47/147, train_loss: 3791.9319\n",
            "48/147, train_loss: 3748.0854\n",
            "49/147, train_loss: 3775.3508\n",
            "50/147, train_loss: 3813.5618\n",
            "51/147, train_loss: 3697.2781\n",
            "52/147, train_loss: 3774.5576\n",
            "53/147, train_loss: 3808.8831\n",
            "54/147, train_loss: 3787.8176\n",
            "55/147, train_loss: 3774.2288\n",
            "56/147, train_loss: 3816.7495\n",
            "57/147, train_loss: 3776.0986\n",
            "58/147, train_loss: 3834.9104\n",
            "59/147, train_loss: 3822.5508\n",
            "60/147, train_loss: 3777.7024\n",
            "61/147, train_loss: 3822.5183\n",
            "62/147, train_loss: 3809.9119\n",
            "63/147, train_loss: 3772.0454\n",
            "64/147, train_loss: 3753.4690\n",
            "65/147, train_loss: 3764.8467\n",
            "66/147, train_loss: 3791.0105\n",
            "67/147, train_loss: 3779.0110\n",
            "68/147, train_loss: 3758.9299\n",
            "69/147, train_loss: 3809.9006\n",
            "70/147, train_loss: 3774.8994\n",
            "71/147, train_loss: 3728.4016\n",
            "72/147, train_loss: 3826.2490\n",
            "73/147, train_loss: 3753.1316\n",
            "74/147, train_loss: 3711.3364\n",
            "75/147, train_loss: 3660.8530\n",
            "76/147, train_loss: 3801.4097\n",
            "77/147, train_loss: 3794.5647\n",
            "78/147, train_loss: 3775.5229\n",
            "79/147, train_loss: 3907.4490\n",
            "80/147, train_loss: 3748.0862\n",
            "81/147, train_loss: 3813.3860\n",
            "82/147, train_loss: 3825.4780\n",
            "83/147, train_loss: 3823.5000\n",
            "84/147, train_loss: 3911.5449\n",
            "85/147, train_loss: 3857.1199\n",
            "86/147, train_loss: 3822.4629\n",
            "87/147, train_loss: 3831.3462\n",
            "88/147, train_loss: 3796.1489\n",
            "89/147, train_loss: 3762.1272\n",
            "90/147, train_loss: 3784.8501\n",
            "91/147, train_loss: 3787.9863\n",
            "92/147, train_loss: 3816.6284\n",
            "93/147, train_loss: 3772.9802\n",
            "94/147, train_loss: 3900.3867\n",
            "95/147, train_loss: 3743.3569\n",
            "96/147, train_loss: 3845.4507\n",
            "97/147, train_loss: 3899.9668\n",
            "98/147, train_loss: 3768.0659\n",
            "99/147, train_loss: 3929.9668\n",
            "100/147, train_loss: 3823.6370\n",
            "101/147, train_loss: 3822.3074\n",
            "102/147, train_loss: 3759.2861\n",
            "103/147, train_loss: 3802.7910\n",
            "104/147, train_loss: 3810.8433\n",
            "105/147, train_loss: 3783.6060\n",
            "106/147, train_loss: 3840.4832\n",
            "107/147, train_loss: 3793.4824\n",
            "108/147, train_loss: 3833.1938\n",
            "109/147, train_loss: 3722.3706\n",
            "110/147, train_loss: 3745.1052\n",
            "111/147, train_loss: 3827.1333\n",
            "112/147, train_loss: 3749.3826\n",
            "113/147, train_loss: 3754.9011\n",
            "114/147, train_loss: 3741.0161\n",
            "115/147, train_loss: 3941.0232\n",
            "116/147, train_loss: 3832.8257\n",
            "117/147, train_loss: 3906.7188\n",
            "118/147, train_loss: 3725.5806\n",
            "119/147, train_loss: 3826.9412\n",
            "120/147, train_loss: 3791.5906\n",
            "121/147, train_loss: 3814.1350\n",
            "122/147, train_loss: 3768.8850\n",
            "123/147, train_loss: 3832.9114\n",
            "124/147, train_loss: 3876.7805\n",
            "125/147, train_loss: 3780.4783\n",
            "126/147, train_loss: 3861.7517\n",
            "127/147, train_loss: 3838.9497\n",
            "128/147, train_loss: 3811.0984\n",
            "129/147, train_loss: 3871.2070\n",
            "130/147, train_loss: 3808.6638\n",
            "131/147, train_loss: 3797.8567\n",
            "132/147, train_loss: 3800.4023\n",
            "133/147, train_loss: 3712.6111\n",
            "134/147, train_loss: 3796.6821\n",
            "135/147, train_loss: 3803.2830\n",
            "136/147, train_loss: 3638.5676\n",
            "137/147, train_loss: 3894.2593\n",
            "138/147, train_loss: 3738.7649\n",
            "139/147, train_loss: 3871.4453\n",
            "140/147, train_loss: 3850.1653\n",
            "141/147, train_loss: 3759.0415\n",
            "142/147, train_loss: 3824.4705\n",
            "143/147, train_loss: 3822.2773\n",
            "144/147, train_loss: 3800.2366\n",
            "145/147, train_loss: 3748.9480\n",
            "146/147, train_loss: 3853.2827\n",
            "147/147, train_loss: 3836.0413\n",
            "148/147, train_loss: 908.2581\n",
            "epoch 51 average loss: 3780.4060\n",
            "Epoch 50: Average validation loss = 9449.888275971283\n",
            "----------\n",
            "epoch 52/60\n",
            "epoch 52 average loss: 3763.6594\n",
            "Epoch 51: Average validation loss = 9410.653703019425\n",
            "----------\n",
            "epoch 53/60\n",
            "epoch 53 average loss: 3733.2234\n",
            "Epoch 52: Average validation loss = 9457.548359638935\n",
            "----------\n",
            "epoch 54/60\n",
            "epoch 54 average loss: 3706.5024\n",
            "Epoch 53: Average validation loss = 9426.50217747044\n",
            "----------\n",
            "epoch 55/60\n",
            "epoch 55 average loss: 3687.1041\n",
            "Epoch 54: Average validation loss = 9514.367108319257\n",
            "----------\n",
            "epoch 56/60\n",
            "1/147, train_loss: 3674.2141\n",
            "2/147, train_loss: 3585.8623\n",
            "3/147, train_loss: 3750.8811\n",
            "4/147, train_loss: 3692.0459\n",
            "5/147, train_loss: 3666.2244\n",
            "6/147, train_loss: 3657.3745\n",
            "7/147, train_loss: 3765.5845\n",
            "8/147, train_loss: 3705.3240\n",
            "9/147, train_loss: 3649.6475\n",
            "10/147, train_loss: 3570.4385\n",
            "11/147, train_loss: 3749.7627\n",
            "12/147, train_loss: 3687.4304\n",
            "13/147, train_loss: 3764.0659\n",
            "14/147, train_loss: 3659.0957\n",
            "15/147, train_loss: 3703.3818\n",
            "16/147, train_loss: 3673.4275\n",
            "17/147, train_loss: 3681.5149\n",
            "18/147, train_loss: 3580.1196\n",
            "19/147, train_loss: 3708.7710\n",
            "20/147, train_loss: 3624.8093\n",
            "21/147, train_loss: 3724.3843\n",
            "22/147, train_loss: 3672.5935\n",
            "23/147, train_loss: 3689.0342\n",
            "24/147, train_loss: 3786.2881\n",
            "25/147, train_loss: 3711.2119\n",
            "26/147, train_loss: 3651.5830\n",
            "27/147, train_loss: 3550.3469\n",
            "28/147, train_loss: 3677.8630\n",
            "29/147, train_loss: 3738.0981\n",
            "30/147, train_loss: 3704.7612\n",
            "31/147, train_loss: 3619.5259\n",
            "32/147, train_loss: 3700.3530\n",
            "33/147, train_loss: 3579.3398\n",
            "34/147, train_loss: 3692.2065\n",
            "35/147, train_loss: 3696.4058\n",
            "36/147, train_loss: 3719.1033\n",
            "37/147, train_loss: 3667.7842\n",
            "38/147, train_loss: 3673.6694\n",
            "39/147, train_loss: 3676.1680\n",
            "40/147, train_loss: 3691.6245\n",
            "41/147, train_loss: 3645.6221\n",
            "42/147, train_loss: 3794.3752\n",
            "43/147, train_loss: 3682.9949\n",
            "44/147, train_loss: 3734.3745\n",
            "45/147, train_loss: 3777.9629\n",
            "46/147, train_loss: 3652.9756\n",
            "47/147, train_loss: 3723.1606\n",
            "48/147, train_loss: 3737.6899\n",
            "49/147, train_loss: 3721.7227\n",
            "50/147, train_loss: 3766.2244\n",
            "51/147, train_loss: 3559.9751\n",
            "52/147, train_loss: 3732.4082\n",
            "53/147, train_loss: 3713.1050\n",
            "54/147, train_loss: 3650.8828\n",
            "55/147, train_loss: 3709.1704\n",
            "56/147, train_loss: 3719.1042\n",
            "57/147, train_loss: 3726.2490\n",
            "58/147, train_loss: 3693.9319\n",
            "59/147, train_loss: 3771.3628\n",
            "60/147, train_loss: 3714.8945\n",
            "61/147, train_loss: 3753.2722\n",
            "62/147, train_loss: 3650.4463\n",
            "63/147, train_loss: 3661.0620\n",
            "64/147, train_loss: 3621.6267\n",
            "65/147, train_loss: 3725.5955\n",
            "66/147, train_loss: 3667.0659\n",
            "67/147, train_loss: 3690.8901\n",
            "68/147, train_loss: 3689.5039\n",
            "69/147, train_loss: 3577.1436\n",
            "70/147, train_loss: 3693.5630\n",
            "71/147, train_loss: 3706.1504\n",
            "72/147, train_loss: 3693.7634\n",
            "73/147, train_loss: 3664.0200\n",
            "74/147, train_loss: 3722.0942\n",
            "75/147, train_loss: 3651.6125\n",
            "76/147, train_loss: 3696.2085\n",
            "77/147, train_loss: 3630.8875\n",
            "78/147, train_loss: 3656.4958\n",
            "79/147, train_loss: 3704.4963\n",
            "80/147, train_loss: 3697.5972\n",
            "81/147, train_loss: 3707.8645\n",
            "82/147, train_loss: 3698.1592\n",
            "83/147, train_loss: 3737.3354\n",
            "84/147, train_loss: 3693.2419\n",
            "85/147, train_loss: 3727.3174\n",
            "86/147, train_loss: 3643.2427\n",
            "87/147, train_loss: 3671.1597\n",
            "88/147, train_loss: 3684.3401\n",
            "89/147, train_loss: 3615.0854\n",
            "90/147, train_loss: 3657.2676\n",
            "91/147, train_loss: 3706.1343\n",
            "92/147, train_loss: 3731.0388\n",
            "93/147, train_loss: 3674.0681\n",
            "94/147, train_loss: 3659.9307\n",
            "95/147, train_loss: 3682.2373\n",
            "96/147, train_loss: 3739.4978\n",
            "97/147, train_loss: 3665.9287\n",
            "98/147, train_loss: 3717.4558\n",
            "99/147, train_loss: 3611.7534\n",
            "100/147, train_loss: 3634.8311\n",
            "101/147, train_loss: 3669.1648\n",
            "102/147, train_loss: 3765.6265\n",
            "103/147, train_loss: 3778.0828\n",
            "104/147, train_loss: 3659.1558\n",
            "105/147, train_loss: 3672.0083\n",
            "106/147, train_loss: 3599.7874\n",
            "107/147, train_loss: 3648.9263\n",
            "108/147, train_loss: 3670.6018\n",
            "109/147, train_loss: 3619.2764\n",
            "110/147, train_loss: 3589.2563\n",
            "111/147, train_loss: 3650.3726\n",
            "112/147, train_loss: 3742.5925\n",
            "113/147, train_loss: 3640.9475\n",
            "114/147, train_loss: 3844.7698\n",
            "115/147, train_loss: 3680.5796\n",
            "116/147, train_loss: 3729.9927\n",
            "117/147, train_loss: 3667.8831\n",
            "118/147, train_loss: 3727.4614\n",
            "119/147, train_loss: 3537.3530\n",
            "120/147, train_loss: 3587.4429\n",
            "121/147, train_loss: 3760.9365\n",
            "122/147, train_loss: 3705.9888\n",
            "123/147, train_loss: 3689.0396\n",
            "124/147, train_loss: 3623.4426\n",
            "125/147, train_loss: 3752.6211\n",
            "126/147, train_loss: 3721.6077\n",
            "127/147, train_loss: 3774.2427\n",
            "128/147, train_loss: 3627.2175\n",
            "129/147, train_loss: 3594.3423\n",
            "130/147, train_loss: 3609.1760\n",
            "131/147, train_loss: 3662.3311\n",
            "132/147, train_loss: 3695.6104\n",
            "133/147, train_loss: 3758.1809\n",
            "134/147, train_loss: 3603.7388\n",
            "135/147, train_loss: 3664.2488\n",
            "136/147, train_loss: 3602.6353\n",
            "137/147, train_loss: 3716.2515\n",
            "138/147, train_loss: 3564.5950\n",
            "139/147, train_loss: 3615.1035\n",
            "140/147, train_loss: 3685.1079\n",
            "141/147, train_loss: 3735.3740\n",
            "142/147, train_loss: 3778.8870\n",
            "143/147, train_loss: 3662.2375\n",
            "144/147, train_loss: 3756.6304\n",
            "145/147, train_loss: 3606.0205\n",
            "146/147, train_loss: 3696.7537\n",
            "147/147, train_loss: 3664.7173\n",
            "148/147, train_loss: 771.8978\n",
            "epoch 56 average loss: 3663.4602\n",
            "Epoch 55: Average validation loss = 9444.75584617821\n",
            "----------\n",
            "epoch 57/60\n",
            "epoch 57 average loss: 3639.0214\n",
            "Epoch 56: Average validation loss = 9457.743395006335\n",
            "----------\n",
            "epoch 58/60\n",
            "epoch 58 average loss: 3621.0982\n",
            "Epoch 57: Average validation loss = 9517.8758379962\n",
            "----------\n",
            "epoch 59/60\n",
            "epoch 59 average loss: 3587.9153\n",
            "Epoch 58: Average validation loss = 9515.29260583826\n",
            "----------\n",
            "epoch 60/60\n",
            "epoch 60 average loss: 3569.8073\n",
            "Epoch 59: Average validation loss = 9428.31077122044\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(trainStepsLoss, label='train_loss')\n",
        "plt.plot(validationEpoch_loss,label='val_loss')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-05T13:48:13.876743Z",
          "iopub.execute_input": "2024-04-05T13:48:13.877885Z",
          "iopub.status.idle": "2024-04-05T13:48:14.188469Z",
          "shell.execute_reply.started": "2024-04-05T13:48:13.877844Z",
          "shell.execute_reply": "2024-04-05T13:48:14.187501Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "L47AtOn1khuf",
        "outputId": "785eb3a1-2c81-44e1-9185-ddf77eb79ac5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function show at 0x7d4f0f1f8180>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 569);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuVaJ5n2khuf",
        "outputId": "2a95f5a9-935c-4cc9-8ac1-2b766e4abb65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelWithAttention(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (attention): GlobalAttention(\n",
              "    (attention): Sequential(\n",
              "      (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Sigmoid()\n",
              "    )\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=23040, out_features=512, bias=True)\n",
              "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (bn6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout2): Dropout(p=0.75, inplace=False)\n",
              "  (output): Linear(in_features=512, out_features=300, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "image = read_image(image_paths[100000]).to(torch.float)\n",
        "image = transform(image).unsqueeze(1).to(device)\n",
        "\n",
        "output = model(image)\n",
        "output_cpu = output.cpu().detach().numpy()\n",
        "\n",
        "label = one_hot_to_label(output_cpu)\n",
        "print(label)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKblf-sukhuf",
        "outputId": "90a49d51-dcd3-4544-8225-a57f5ef00add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IjIC9\n"
          ]
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": [
        "gt_list[100000]"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2ia7DxBvkhuf",
        "outputId": "b4cbfb1d-6655-44f2-a74d-46cf64bf7f1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t2i1Q'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "transform(read_image(image_paths[10000]).to(torch.float)).to(device).shape"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyWsZFrRkhuf",
        "outputId": "b709c55a-acaa-42aa-f008-52ba559597cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 40, 150])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "imagemm=cv2.imread(image_paths[100000])\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(imagemm)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "LsN8EG7fkhuf",
        "outputId": "f6697674-b6f2-499c-d54a-4831be0e0c53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26
    }
  ]
}